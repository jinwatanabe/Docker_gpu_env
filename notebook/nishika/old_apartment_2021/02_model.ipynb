{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "significant-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre6 import data_pre\n",
    "from input_data import input_df\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "synthetic-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "df = input_df()\n",
    "df = data_pre(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "specialized-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/tmp/working/dataset/nishika/old_apartment_2020/test.csv\", index_col=0)\n",
    "\n",
    "df_test = data_pre(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "returning-dialogue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 651975 entries, 1117225 to 47008266\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Non-Null Count   Dtype   \n",
      "---  ------        --------------   -----   \n",
      " 0   都道府県名         651975 non-null  category\n",
      " 1   市区町村名         651975 non-null  category\n",
      " 2   地区名           651318 non-null  category\n",
      " 3   最寄駅：名称        649342 non-null  category\n",
      " 4   最寄駅：距離（分）     628916 non-null  float64 \n",
      " 5   間取り           629546 non-null  category\n",
      " 6   面積（㎡）         651975 non-null  float64 \n",
      " 7   建築年           633280 non-null  float64 \n",
      " 8   建物の構造         637098 non-null  category\n",
      " 9   用途            601333 non-null  category\n",
      " 10  今後の利用目的       288948 non-null  category\n",
      " 11  都市計画          633162 non-null  category\n",
      " 12  建ぺい率（％）       629168 non-null  float64 \n",
      " 13  容積率（％）        629168 non-null  float64 \n",
      " 14  取引時点          651975 non-null  float64 \n",
      " 15  改装            593301 non-null  category\n",
      " 16  取引の事情等        18397 non-null   category\n",
      " 17  取引価格（総額）_log  651975 non-null  float64 \n",
      " 18  緯度            651975 non-null  float64 \n",
      " 19  経度            651975 non-null  float64 \n",
      " 20  クラスタ平均        651975 non-null  float64 \n",
      " 21  平均価格          651975 non-null  float64 \n",
      "dtypes: category(11), float64(11)\n",
      "memory usage: 68.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "obvious-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('クラスタ平均', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enormous-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop('クラスタ平均', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bright-moral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import lightgbm\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.2)\n",
    "\n",
    "col = \"取引価格（総額）_log\"\n",
    "train_y = df_train[col]\n",
    "train_x = df_train.drop(col, axis=1)\n",
    "\n",
    "val_y = df_val[col]\n",
    "val_x = df_val.drop(col, axis=1)\n",
    "\n",
    "trains = lgb.Dataset(train_x, train_y)\n",
    "valids = lgb.Dataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rational-repair",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-06 09:10:03,876]\u001b[0m A new study created in memory with name: no-name-499e6ab3-597a-4485-aea6-8013e5a4a794\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's l1: 0.0783438\n",
      "[400]\tvalid_0's l1: 0.0767136\n",
      "[600]\tvalid_0's l1: 0.0761967\n",
      "[800]\tvalid_0's l1: 0.0759311\n",
      "[1000]\tvalid_0's l1: 0.0757718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0757718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075772:  14%|#4        | 1/7 [00:36<03:36, 36.05s/it]\u001b[32m[I 2021-06-06 09:10:39,929]\u001b[0m Trial 0 finished with value: 0.07577184787455635 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.07577184787455635.\u001b[0m\n",
      "feature_fraction, val_score: 0.075772:  14%|#4        | 1/7 [00:36<03:36, 36.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0783957\n",
      "[400]\tvalid_0's l1: 0.0768244\n",
      "[600]\tvalid_0's l1: 0.0763027\n",
      "[800]\tvalid_0's l1: 0.076097\n",
      "[1000]\tvalid_0's l1: 0.0759538\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0759538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075772:  29%|##8       | 2/7 [01:25<03:39, 43.93s/it]\u001b[32m[I 2021-06-06 09:11:29,373]\u001b[0m Trial 1 finished with value: 0.07595376325388709 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.07577184787455635.\u001b[0m\n",
      "feature_fraction, val_score: 0.075772:  29%|##8       | 2/7 [01:25<03:39, 43.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0780569\n",
      "[400]\tvalid_0's l1: 0.0764329\n",
      "[600]\tvalid_0's l1: 0.0759039\n",
      "[800]\tvalid_0's l1: 0.0756456\n",
      "[1000]\tvalid_0's l1: 0.0754899\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[993]\tvalid_0's l1: 0.0754883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075488:  43%|####2     | 3/7 [02:03<02:45, 41.43s/it]\u001b[32m[I 2021-06-06 09:12:07,841]\u001b[0m Trial 2 finished with value: 0.07548827540486175 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.07548827540486175.\u001b[0m\n",
      "feature_fraction, val_score: 0.075488:  43%|####2     | 3/7 [02:03<02:45, 41.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.078419\n",
      "[400]\tvalid_0's l1: 0.0769148\n",
      "[600]\tvalid_0's l1: 0.0763583\n",
      "[800]\tvalid_0's l1: 0.0761734\n",
      "[1000]\tvalid_0's l1: 0.0760398\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0760398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075488:  57%|#####7    | 4/7 [02:50<02:09, 43.28s/it]\u001b[32m[I 2021-06-06 09:12:53,963]\u001b[0m Trial 3 finished with value: 0.07603977833763835 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.07548827540486175.\u001b[0m\n",
      "feature_fraction, val_score: 0.075488:  57%|#####7    | 4/7 [02:50<02:09, 43.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0783287\n",
      "[400]\tvalid_0's l1: 0.0764014\n",
      "[600]\tvalid_0's l1: 0.0758457\n",
      "[800]\tvalid_0's l1: 0.0754617\n",
      "[1000]\tvalid_0's l1: 0.0753158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0753158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075316:  71%|#######1  | 5/7 [03:23<01:19, 39.86s/it]\u001b[32m[I 2021-06-06 09:13:27,760]\u001b[0m Trial 4 finished with value: 0.07531576849407347 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.07531576849407347.\u001b[0m\n",
      "feature_fraction, val_score: 0.075316:  71%|#######1  | 5/7 [03:23<01:19, 39.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0783215\n",
      "[400]\tvalid_0's l1: 0.0767449\n",
      "[600]\tvalid_0's l1: 0.0762093\n",
      "[800]\tvalid_0's l1: 0.0759405\n",
      "[1000]\tvalid_0's l1: 0.0758285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0758278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075316:  86%|########5 | 6/7 [04:09<00:41, 41.86s/it]\u001b[32m[I 2021-06-06 09:14:13,494]\u001b[0m Trial 5 finished with value: 0.07582779839619831 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.07531576849407347.\u001b[0m\n",
      "feature_fraction, val_score: 0.075316:  86%|########5 | 6/7 [04:09<00:41, 41.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0788497\n",
      "[400]\tvalid_0's l1: 0.0765785\n",
      "[600]\tvalid_0's l1: 0.0760173\n",
      "[800]\tvalid_0's l1: 0.0756229\n",
      "[1000]\tvalid_0's l1: 0.0754084\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0754084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075316: 100%|##########| 7/7 [04:46<00:00, 40.31s/it]\u001b[32m[I 2021-06-06 09:14:50,632]\u001b[0m Trial 6 finished with value: 0.07540837722103352 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.07531576849407347.\u001b[0m\n",
      "feature_fraction, val_score: 0.075316: 100%|##########| 7/7 [04:46<00:00, 40.96s/it]\n",
      "num_leaves, val_score: 0.075316:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0750586\n",
      "[400]\tvalid_0's l1: 0.0749234\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's l1: 0.074874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074874:   5%|5         | 1/20 [00:51<16:23, 51.75s/it]\u001b[32m[I 2021-06-06 09:15:42,394]\u001b[0m Trial 7 finished with value: 0.07487401706251211 and parameters: {'num_leaves': 224}. Best is trial 7 with value: 0.07487401706251211.\u001b[0m\n",
      "num_leaves, val_score: 0.074874:   5%|5         | 1/20 [00:51<16:23, 51.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0756367\n",
      "[400]\tvalid_0's l1: 0.0750854\n",
      "[600]\tvalid_0's l1: 0.074939\n",
      "[800]\tvalid_0's l1: 0.0748584\n",
      "[1000]\tvalid_0's l1: 0.0748285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0748281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074828:  10%|#         | 2/20 [01:43<15:30, 51.67s/it]\u001b[32m[I 2021-06-06 09:16:34,013]\u001b[0m Trial 8 finished with value: 0.07482814744129486 and parameters: {'num_leaves': 101}. Best is trial 8 with value: 0.07482814744129486.\u001b[0m\n",
      "num_leaves, val_score: 0.074828:  10%|#         | 2/20 [01:43<15:30, 51.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0766196\n",
      "[400]\tvalid_0's l1: 0.075492\n",
      "[600]\tvalid_0's l1: 0.0752303\n",
      "[800]\tvalid_0's l1: 0.0750405\n",
      "[1000]\tvalid_0's l1: 0.0749562\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.074956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074828:  15%|#5        | 3/20 [02:30<14:00, 49.46s/it]\u001b[32m[I 2021-06-06 09:17:20,836]\u001b[0m Trial 9 finished with value: 0.07495599020812813 and parameters: {'num_leaves': 54}. Best is trial 8 with value: 0.07482814744129486.\u001b[0m\n",
      "num_leaves, val_score: 0.074828:  15%|#5        | 3/20 [02:30<14:00, 49.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760626\n",
      "[400]\tvalid_0's l1: 0.0751575\n",
      "[600]\tvalid_0's l1: 0.0749346\n",
      "[800]\tvalid_0's l1: 0.0747899\n",
      "[1000]\tvalid_0's l1: 0.0747254\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[991]\tvalid_0's l1: 0.074724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  20%|##        | 4/20 [03:22<13:27, 50.49s/it]\u001b[32m[I 2021-06-06 09:18:12,919]\u001b[0m Trial 10 finished with value: 0.07472398436627112 and parameters: {'num_leaves': 74}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  20%|##        | 4/20 [03:22<13:27, 50.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.075248\n",
      "[400]\tvalid_0's l1: 0.0749528\n",
      "Early stopping, best iteration is:\n",
      "[467]\tvalid_0's l1: 0.0749372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  25%|##5       | 5/20 [04:12<12:36, 50.46s/it]\u001b[32m[I 2021-06-06 09:19:03,323]\u001b[0m Trial 11 finished with value: 0.07493717422450474 and parameters: {'num_leaves': 181}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  25%|##5       | 5/20 [04:12<12:36, 50.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751614\n",
      "[400]\tvalid_0's l1: 0.0749935\n",
      "Early stopping, best iteration is:\n",
      "[427]\tvalid_0's l1: 0.0749828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  30%|###       | 6/20 [05:03<11:50, 50.73s/it]\u001b[32m[I 2021-06-06 09:19:54,566]\u001b[0m Trial 12 finished with value: 0.0749827763537637 and parameters: {'num_leaves': 201}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  30%|###       | 6/20 [05:03<11:50, 50.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0774494\n",
      "[400]\tvalid_0's l1: 0.0759873\n",
      "[600]\tvalid_0's l1: 0.0755334\n",
      "[800]\tvalid_0's l1: 0.0752826\n",
      "[1000]\tvalid_0's l1: 0.0751186\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0751183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  35%|###5      | 7/20 [05:46<10:24, 48.07s/it]\u001b[32m[I 2021-06-06 09:20:37,155]\u001b[0m Trial 13 finished with value: 0.07511828709333981 and parameters: {'num_leaves': 40}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  35%|###5      | 7/20 [05:46<10:24, 48.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0750509\n",
      "[400]\tvalid_0's l1: 0.0749069\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid_0's l1: 0.0748692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  40%|####      | 8/20 [06:37<09:47, 48.96s/it]\u001b[32m[I 2021-06-06 09:21:28,033]\u001b[0m Trial 14 finished with value: 0.0748691510837714 and parameters: {'num_leaves': 218}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  40%|####      | 8/20 [06:37<09:47, 48.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0756367\n",
      "[400]\tvalid_0's l1: 0.0750854\n",
      "[600]\tvalid_0's l1: 0.074939\n",
      "[800]\tvalid_0's l1: 0.0748584\n",
      "[1000]\tvalid_0's l1: 0.0748285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0748281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  45%|####5     | 9/20 [07:37<09:37, 52.53s/it]\u001b[32m[I 2021-06-06 09:22:28,396]\u001b[0m Trial 15 finished with value: 0.07482814744129486 and parameters: {'num_leaves': 101}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  45%|####5     | 9/20 [07:37<09:37, 52.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0841492\n",
      "[400]\tvalid_0's l1: 0.0801295\n",
      "[600]\tvalid_0's l1: 0.0786139\n",
      "[800]\tvalid_0's l1: 0.0778948\n",
      "[1000]\tvalid_0's l1: 0.0775176\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0775176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  50%|#####     | 10/20 [08:07<07:36, 45.63s/it]\u001b[32m[I 2021-06-06 09:22:58,596]\u001b[0m Trial 16 finished with value: 0.07751761060384847 and parameters: {'num_leaves': 12}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  50%|#####     | 10/20 [08:07<07:36, 45.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752282\n",
      "[400]\tvalid_0's l1: 0.0749843\n",
      "[600]\tvalid_0's l1: 0.0749051\n",
      "Early stopping, best iteration is:\n",
      "[673]\tvalid_0's l1: 0.0748803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  55%|#####5    | 11/20 [09:09<07:35, 50.57s/it]\u001b[32m[I 2021-06-06 09:24:00,358]\u001b[0m Trial 17 finished with value: 0.07488034500020298 and parameters: {'num_leaves': 162}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  55%|#####5    | 11/20 [09:09<07:35, 50.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0755863\n",
      "[400]\tvalid_0's l1: 0.0750142\n",
      "[600]\tvalid_0's l1: 0.0748796\n",
      "[800]\tvalid_0's l1: 0.0748064\n",
      "[1000]\tvalid_0's l1: 0.0747835\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[991]\tvalid_0's l1: 0.0747803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  60%|######    | 12/20 [10:07<07:00, 52.62s/it]\u001b[32m[I 2021-06-06 09:24:57,679]\u001b[0m Trial 18 finished with value: 0.0747802859777437 and parameters: {'num_leaves': 103}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  60%|######    | 12/20 [10:07<07:00, 52.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0754319\n",
      "[400]\tvalid_0's l1: 0.0749301\n",
      "[600]\tvalid_0's l1: 0.0748653\n",
      "[800]\tvalid_0's l1: 0.0748194\n",
      "[1000]\tvalid_0's l1: 0.0747712\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.074771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  65%|######5   | 13/20 [11:07<06:25, 55.07s/it]\u001b[32m[I 2021-06-06 09:25:58,375]\u001b[0m Trial 19 finished with value: 0.07477097801775943 and parameters: {'num_leaves': 118}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  65%|######5   | 13/20 [11:07<06:25, 55.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752994\n",
      "[400]\tvalid_0's l1: 0.0749395\n",
      "[600]\tvalid_0's l1: 0.074894\n",
      "[800]\tvalid_0's l1: 0.0748231\n",
      "Early stopping, best iteration is:\n",
      "[824]\tvalid_0's l1: 0.0748169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  70%|#######   | 14/20 [12:16<05:54, 59.10s/it]\u001b[32m[I 2021-06-06 09:27:06,777]\u001b[0m Trial 20 finished with value: 0.0748168902486215 and parameters: {'num_leaves': 145}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  70%|#######   | 14/20 [12:16<05:54, 59.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0763115\n",
      "[400]\tvalid_0's l1: 0.0753687\n",
      "[600]\tvalid_0's l1: 0.0750536\n",
      "[800]\tvalid_0's l1: 0.0748696\n",
      "[1000]\tvalid_0's l1: 0.0747602\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0747602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074724:  75%|#######5  | 15/20 [13:04<04:39, 55.92s/it]\u001b[32m[I 2021-06-06 09:27:55,338]\u001b[0m Trial 21 finished with value: 0.07476022309231534 and parameters: {'num_leaves': 61}. Best is trial 10 with value: 0.07472398436627112.\u001b[0m\n",
      "num_leaves, val_score: 0.074724:  75%|#######5  | 15/20 [13:04<04:39, 55.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761382\n",
      "[400]\tvalid_0's l1: 0.0752437\n",
      "[600]\tvalid_0's l1: 0.0749513\n",
      "[800]\tvalid_0's l1: 0.0747351\n",
      "[1000]\tvalid_0's l1: 0.0746528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.074652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074652:  80%|########  | 16/20 [13:57<03:39, 54.98s/it]\u001b[32m[I 2021-06-06 09:28:48,118]\u001b[0m Trial 22 finished with value: 0.07465196066299365 and parameters: {'num_leaves': 67}. Best is trial 22 with value: 0.07465196066299365.\u001b[0m\n",
      "num_leaves, val_score: 0.074652:  80%|########  | 16/20 [13:57<03:39, 54.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0828845\n",
      "[400]\tvalid_0's l1: 0.0791557\n",
      "[600]\tvalid_0's l1: 0.0779529\n",
      "[800]\tvalid_0's l1: 0.0773511\n",
      "[1000]\tvalid_0's l1: 0.0770038\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0770036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074652:  85%|########5 | 17/20 [14:27<02:22, 47.39s/it]\u001b[32m[I 2021-06-06 09:29:17,865]\u001b[0m Trial 23 finished with value: 0.077003624837161 and parameters: {'num_leaves': 14}. Best is trial 22 with value: 0.07465196066299365.\u001b[0m\n",
      "num_leaves, val_score: 0.074652:  85%|########5 | 17/20 [14:27<02:22, 47.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761651\n",
      "[400]\tvalid_0's l1: 0.0752724\n",
      "[600]\tvalid_0's l1: 0.0750558\n",
      "[800]\tvalid_0's l1: 0.0749212\n",
      "[1000]\tvalid_0's l1: 0.0748192\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[991]\tvalid_0's l1: 0.0748169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074652:  90%|######### | 18/20 [15:18<01:37, 48.64s/it]\u001b[32m[I 2021-06-06 09:30:09,431]\u001b[0m Trial 24 finished with value: 0.07481686530163553 and parameters: {'num_leaves': 70}. Best is trial 22 with value: 0.07465196066299365.\u001b[0m\n",
      "num_leaves, val_score: 0.074652:  90%|######### | 18/20 [15:18<01:37, 48.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751424\n",
      "[400]\tvalid_0's l1: 0.0750955\n",
      "Early stopping, best iteration is:\n",
      "[302]\tvalid_0's l1: 0.075049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074652:  95%|#########5| 19/20 [16:05<00:48, 48.00s/it]\u001b[32m[I 2021-06-06 09:30:55,937]\u001b[0m Trial 25 finished with value: 0.07504896154416073 and parameters: {'num_leaves': 254}. Best is trial 22 with value: 0.07465196066299365.\u001b[0m\n",
      "num_leaves, val_score: 0.074652:  95%|#########5| 19/20 [16:05<00:48, 48.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0758974\n",
      "[400]\tvalid_0's l1: 0.0752164\n",
      "[600]\tvalid_0's l1: 0.0749464\n",
      "[800]\tvalid_0's l1: 0.0748252\n",
      "[1000]\tvalid_0's l1: 0.0747461\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0747461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074652: 100%|##########| 20/20 [16:57<00:00, 49.16s/it]\u001b[32m[I 2021-06-06 09:31:47,790]\u001b[0m Trial 26 finished with value: 0.07474610291971245 and parameters: {'num_leaves': 82}. Best is trial 22 with value: 0.07465196066299365.\u001b[0m\n",
      "num_leaves, val_score: 0.074652: 100%|##########| 20/20 [16:57<00:00, 50.86s/it]\n",
      "bagging, val_score: 0.074652:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0765673\n",
      "[400]\tvalid_0's l1: 0.0757897\n",
      "[600]\tvalid_0's l1: 0.0754569\n",
      "[800]\tvalid_0's l1: 0.0752549\n",
      "[1000]\tvalid_0's l1: 0.07517\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[991]\tvalid_0's l1: 0.0751578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  10%|#         | 1/10 [02:23<21:28, 143.15s/it]\u001b[32m[I 2021-06-06 09:34:10,949]\u001b[0m Trial 27 finished with value: 0.07515778356574454 and parameters: {'bagging_fraction': 0.8106384276683711, 'bagging_freq': 6}. Best is trial 27 with value: 0.07515778356574454.\u001b[0m\n",
      "bagging, val_score: 0.074652:  10%|#         | 1/10 [02:23<21:28, 143.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0764537\n",
      "[400]\tvalid_0's l1: 0.0755182\n",
      "[600]\tvalid_0's l1: 0.0752402\n",
      "[800]\tvalid_0's l1: 0.0750663\n",
      "[1000]\tvalid_0's l1: 0.0749942\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's l1: 0.074993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  20%|##        | 2/10 [04:34<18:09, 136.20s/it]\u001b[32m[I 2021-06-06 09:36:22,284]\u001b[0m Trial 28 finished with value: 0.07499298674860788 and parameters: {'bagging_fraction': 0.8792643360854058, 'bagging_freq': 3}. Best is trial 28 with value: 0.07499298674860788.\u001b[0m\n",
      "bagging, val_score: 0.074652:  20%|##        | 2/10 [04:34<18:09, 136.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0764671\n",
      "[400]\tvalid_0's l1: 0.0756169\n",
      "[600]\tvalid_0's l1: 0.0753008\n",
      "[800]\tvalid_0's l1: 0.0751234\n",
      "[1000]\tvalid_0's l1: 0.0750678\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[992]\tvalid_0's l1: 0.0750622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  30%|###       | 3/10 [06:51<15:56, 136.70s/it]\u001b[32m[I 2021-06-06 09:38:39,589]\u001b[0m Trial 29 finished with value: 0.07506224445315465 and parameters: {'bagging_fraction': 0.8704223168956084, 'bagging_freq': 2}. Best is trial 28 with value: 0.07499298674860788.\u001b[0m\n",
      "bagging, val_score: 0.074652:  30%|###       | 3/10 [06:51<15:56, 136.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0769637\n",
      "[400]\tvalid_0's l1: 0.0761633\n",
      "[600]\tvalid_0's l1: 0.0758549\n",
      "[800]\tvalid_0's l1: 0.075611\n",
      "[1000]\tvalid_0's l1: 0.0755284\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's l1: 0.0755195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  40%|####      | 4/10 [09:34<14:41, 146.98s/it]\u001b[32m[I 2021-06-06 09:41:22,314]\u001b[0m Trial 30 finished with value: 0.07551951725846774 and parameters: {'bagging_fraction': 0.7296561884057293, 'bagging_freq': 5}. Best is trial 28 with value: 0.07499298674860788.\u001b[0m\n",
      "bagging, val_score: 0.074652:  40%|####      | 4/10 [09:34<14:41, 146.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0775605\n",
      "[400]\tvalid_0's l1: 0.0767167\n",
      "[600]\tvalid_0's l1: 0.0764033\n",
      "[800]\tvalid_0's l1: 0.0761933\n",
      "[1000]\tvalid_0's l1: 0.076137\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[991]\tvalid_0's l1: 0.0761132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  50%|#####     | 5/10 [12:22<12:52, 154.44s/it]\u001b[32m[I 2021-06-06 09:44:09,979]\u001b[0m Trial 31 finished with value: 0.07611318592206616 and parameters: {'bagging_fraction': 0.5461300912999618, 'bagging_freq': 3}. Best is trial 28 with value: 0.07499298674860788.\u001b[0m\n",
      "bagging, val_score: 0.074652:  50%|#####     | 5/10 [12:22<12:52, 154.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0768065\n",
      "[400]\tvalid_0's l1: 0.0760625\n",
      "[600]\tvalid_0's l1: 0.0757132\n",
      "[800]\tvalid_0's l1: 0.0755276\n",
      "[1000]\tvalid_0's l1: 0.075448\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's l1: 0.0754283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  60%|######    | 6/10 [15:05<10:29, 157.39s/it]\u001b[32m[I 2021-06-06 09:46:53,112]\u001b[0m Trial 32 finished with value: 0.07542833255915951 and parameters: {'bagging_fraction': 0.7412091219230325, 'bagging_freq': 5}. Best is trial 28 with value: 0.07499298674860788.\u001b[0m\n",
      "bagging, val_score: 0.074652:  60%|######    | 6/10 [15:05<10:29, 157.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0778974\n",
      "[400]\tvalid_0's l1: 0.0770954\n",
      "[600]\tvalid_0's l1: 0.0766999\n",
      "[800]\tvalid_0's l1: 0.0764802\n",
      "[1000]\tvalid_0's l1: 0.0764423\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[976]\tvalid_0's l1: 0.0763787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  70%|#######   | 7/10 [17:44<07:53, 157.92s/it]\u001b[32m[I 2021-06-06 09:49:32,102]\u001b[0m Trial 33 finished with value: 0.0763787407281653 and parameters: {'bagging_fraction': 0.4796274456755641, 'bagging_freq': 5}. Best is trial 28 with value: 0.07499298674860788.\u001b[0m\n",
      "bagging, val_score: 0.074652:  70%|#######   | 7/10 [17:44<07:53, 157.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.076401\n",
      "[400]\tvalid_0's l1: 0.0755694\n",
      "[600]\tvalid_0's l1: 0.0752609\n",
      "[800]\tvalid_0's l1: 0.0750749\n",
      "[1000]\tvalid_0's l1: 0.0749822\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[992]\tvalid_0's l1: 0.0749713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  80%|########  | 8/10 [20:00<05:02, 151.16s/it]\u001b[32m[I 2021-06-06 09:51:48,784]\u001b[0m Trial 34 finished with value: 0.07497126676498794 and parameters: {'bagging_fraction': 0.866857172084377, 'bagging_freq': 4}. Best is trial 34 with value: 0.07497126676498794.\u001b[0m\n",
      "bagging, val_score: 0.074652:  80%|########  | 8/10 [20:00<05:02, 151.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761733\n",
      "[400]\tvalid_0's l1: 0.075375\n",
      "[600]\tvalid_0's l1: 0.0751274\n",
      "[800]\tvalid_0's l1: 0.0749318\n",
      "[1000]\tvalid_0's l1: 0.0748163\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[988]\tvalid_0's l1: 0.0748139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652:  90%|######### | 9/10 [21:33<02:12, 132.78s/it]\u001b[32m[I 2021-06-06 09:53:21,149]\u001b[0m Trial 35 finished with value: 0.07481387527840892 and parameters: {'bagging_fraction': 0.9765681720871107, 'bagging_freq': 4}. Best is trial 35 with value: 0.07481387527840892.\u001b[0m\n",
      "bagging, val_score: 0.074652:  90%|######### | 9/10 [21:33<02:12, 132.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761945\n",
      "[400]\tvalid_0's l1: 0.0753879\n",
      "[600]\tvalid_0's l1: 0.0751269\n",
      "[800]\tvalid_0's l1: 0.0749994\n",
      "[1000]\tvalid_0's l1: 0.0749136\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0749136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074652: 100%|##########| 10/10 [23:19<00:00, 124.65s/it]\u001b[32m[I 2021-06-06 09:55:07,596]\u001b[0m Trial 36 finished with value: 0.07491361764297846 and parameters: {'bagging_fraction': 0.9434801319262937, 'bagging_freq': 6}. Best is trial 35 with value: 0.07481387527840892.\u001b[0m\n",
      "bagging, val_score: 0.074652: 100%|##########| 10/10 [23:19<00:00, 139.98s/it]\n",
      "feature_fraction_stage2, val_score: 0.074652:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761382\n",
      "[400]\tvalid_0's l1: 0.0752437\n",
      "[600]\tvalid_0's l1: 0.0749513\n",
      "[800]\tvalid_0's l1: 0.0747351\n",
      "[1000]\tvalid_0's l1: 0.0746528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.074652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074652:  17%|#6        | 1/6 [00:50<04:14, 50.90s/it]\u001b[32m[I 2021-06-06 09:55:58,507]\u001b[0m Trial 37 finished with value: 0.07465196066299365 and parameters: {'feature_fraction': 0.484}. Best is trial 37 with value: 0.07465196066299365.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074652:  17%|#6        | 1/6 [00:50<04:14, 50.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0766432\n",
      "[400]\tvalid_0's l1: 0.0754601\n",
      "[600]\tvalid_0's l1: 0.0751633\n",
      "[800]\tvalid_0's l1: 0.0750118\n",
      "[1000]\tvalid_0's l1: 0.0749068\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.074906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074652:  33%|###3      | 2/6 [01:38<03:15, 48.97s/it]\u001b[32m[I 2021-06-06 09:56:46,119]\u001b[0m Trial 38 finished with value: 0.07490596124283248 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.07465196066299365.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074652:  33%|###3      | 2/6 [01:38<03:15, 48.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760379\n",
      "[400]\tvalid_0's l1: 0.0752404\n",
      "[600]\tvalid_0's l1: 0.0750574\n",
      "[800]\tvalid_0's l1: 0.0749801\n",
      "[1000]\tvalid_0's l1: 0.0749127\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's l1: 0.0749124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074652:  50%|#####     | 3/6 [02:29<02:29, 49.70s/it]\u001b[32m[I 2021-06-06 09:57:36,697]\u001b[0m Trial 39 finished with value: 0.07491240270409845 and parameters: {'feature_fraction': 0.58}. Best is trial 37 with value: 0.07465196066299365.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074652:  50%|#####     | 3/6 [02:29<02:29, 49.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0762861\n",
      "[400]\tvalid_0's l1: 0.0753488\n",
      "[600]\tvalid_0's l1: 0.0750724\n",
      "[800]\tvalid_0's l1: 0.0748785\n",
      "[1000]\tvalid_0's l1: 0.0747521\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's l1: 0.0747518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074652:  67%|######6   | 4/6 [03:12<01:34, 47.03s/it]\u001b[32m[I 2021-06-06 09:58:19,633]\u001b[0m Trial 40 finished with value: 0.07475178222853206 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.07465196066299365.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074652:  67%|######6   | 4/6 [03:12<01:34, 47.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761382\n",
      "[400]\tvalid_0's l1: 0.0752437\n",
      "[600]\tvalid_0's l1: 0.0749513\n",
      "[800]\tvalid_0's l1: 0.0747351\n",
      "[1000]\tvalid_0's l1: 0.0746528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.074652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074652:  83%|########3 | 5/6 [03:59<00:47, 47.21s/it]\u001b[32m[I 2021-06-06 09:59:07,159]\u001b[0m Trial 41 finished with value: 0.07465196066299365 and parameters: {'feature_fraction': 0.516}. Best is trial 37 with value: 0.07465196066299365.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074652:  83%|########3 | 5/6 [03:59<00:47, 47.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760255\n",
      "[400]\tvalid_0's l1: 0.0752436\n",
      "[600]\tvalid_0's l1: 0.0750664\n",
      "[800]\tvalid_0's l1: 0.0749245\n",
      "[1000]\tvalid_0's l1: 0.0748743\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[994]\tvalid_0's l1: 0.0748717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074652: 100%|##########| 6/6 [04:49<00:00, 48.22s/it]\u001b[32m[I 2021-06-06 09:59:57,327]\u001b[0m Trial 42 finished with value: 0.07487167296625588 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 37 with value: 0.07465196066299365.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074652: 100%|##########| 6/6 [04:49<00:00, 48.29s/it]\n",
      "regularization_factors, val_score: 0.074652:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761289\n",
      "[400]\tvalid_0's l1: 0.075207\n",
      "[600]\tvalid_0's l1: 0.0749457\n",
      "[800]\tvalid_0's l1: 0.0748036\n",
      "[1000]\tvalid_0's l1: 0.074738\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.074738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074652:   5%|5         | 1/20 [00:50<16:07, 50.91s/it]\u001b[32m[I 2021-06-06 10:00:48,244]\u001b[0m Trial 43 finished with value: 0.07473798778266728 and parameters: {'lambda_l1': 0.014080886758001246, 'lambda_l2': 0.09064585897735962}. Best is trial 43 with value: 0.07473798778266728.\u001b[0m\n",
      "regularization_factors, val_score: 0.074652:   5%|5         | 1/20 [00:50<16:07, 50.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761339\n",
      "[400]\tvalid_0's l1: 0.0752649\n",
      "[600]\tvalid_0's l1: 0.0750135\n",
      "[800]\tvalid_0's l1: 0.0748508\n",
      "[1000]\tvalid_0's l1: 0.0747755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0747755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074652:  10%|#         | 2/20 [01:39<14:49, 49.41s/it]\u001b[32m[I 2021-06-06 10:01:36,599]\u001b[0m Trial 44 finished with value: 0.07477552837895711 and parameters: {'lambda_l1': 6.15467034185251e-06, 'lambda_l2': 3.9341524334608575}. Best is trial 43 with value: 0.07473798778266728.\u001b[0m\n",
      "regularization_factors, val_score: 0.074652:  10%|#         | 2/20 [01:39<14:49, 49.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761235\n",
      "[400]\tvalid_0's l1: 0.0752811\n",
      "[600]\tvalid_0's l1: 0.0750329\n",
      "[800]\tvalid_0's l1: 0.0748815\n",
      "[1000]\tvalid_0's l1: 0.0747734\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[990]\tvalid_0's l1: 0.0747725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074652:  15%|#5        | 3/20 [02:24<13:24, 47.33s/it]\u001b[32m[I 2021-06-06 10:02:21,449]\u001b[0m Trial 45 finished with value: 0.07477246390371164 and parameters: {'lambda_l1': 6.222282350743946e-05, 'lambda_l2': 2.9347740588270675e-06}. Best is trial 43 with value: 0.07473798778266728.\u001b[0m\n",
      "regularization_factors, val_score: 0.074652:  15%|#5        | 3/20 [02:24<13:24, 47.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0758744\n",
      "[400]\tvalid_0's l1: 0.0746875\n",
      "[600]\tvalid_0's l1: 0.0744194\n",
      "[800]\tvalid_0's l1: 0.0743161\n",
      "Early stopping, best iteration is:\n",
      "[826]\tvalid_0's l1: 0.0743108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  20%|##        | 4/20 [03:20<13:34, 50.90s/it]\u001b[32m[I 2021-06-06 10:03:17,818]\u001b[0m Trial 46 finished with value: 0.07431082760188162 and parameters: {'lambda_l1': 5.807654500796016, 'lambda_l2': 1.9110459650612784e-08}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  20%|##        | 4/20 [03:20<13:34, 50.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760873\n",
      "[400]\tvalid_0's l1: 0.0751895\n",
      "[600]\tvalid_0's l1: 0.0749453\n",
      "[800]\tvalid_0's l1: 0.074795\n",
      "[1000]\tvalid_0's l1: 0.0747116\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[990]\tvalid_0's l1: 0.0747116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  25%|##5       | 5/20 [04:05<12:08, 48.60s/it]\u001b[32m[I 2021-06-06 10:04:02,346]\u001b[0m Trial 47 finished with value: 0.07471157317452413 and parameters: {'lambda_l1': 1.2756461816378705e-05, 'lambda_l2': 0.8254303532168152}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  25%|##5       | 5/20 [04:05<12:08, 48.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761762\n",
      "[400]\tvalid_0's l1: 0.0752547\n",
      "[600]\tvalid_0's l1: 0.0750008\n",
      "[800]\tvalid_0's l1: 0.0748309\n",
      "[1000]\tvalid_0's l1: 0.0747447\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0747447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  30%|###       | 6/20 [04:50<11:03, 47.39s/it]\u001b[32m[I 2021-06-06 10:04:47,389]\u001b[0m Trial 48 finished with value: 0.07474471842620159 and parameters: {'lambda_l1': 0.08229423293699739, 'lambda_l2': 4.90176375572664e-05}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  30%|###       | 6/20 [04:50<11:03, 47.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761802\n",
      "[400]\tvalid_0's l1: 0.0752462\n",
      "[600]\tvalid_0's l1: 0.0750073\n",
      "[800]\tvalid_0's l1: 0.0749028\n",
      "[1000]\tvalid_0's l1: 0.0748088\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.074808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  35%|###5      | 7/20 [05:33<10:00, 46.16s/it]\u001b[32m[I 2021-06-06 10:05:31,030]\u001b[0m Trial 49 finished with value: 0.07480795811620802 and parameters: {'lambda_l1': 0.0003449347349000712, 'lambda_l2': 0.0005815257358536309}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  35%|###5      | 7/20 [05:33<10:00, 46.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0759732\n",
      "[400]\tvalid_0's l1: 0.0748699\n",
      "[600]\tvalid_0's l1: 0.0746846\n",
      "[800]\tvalid_0's l1: 0.0746128\n",
      "Early stopping, best iteration is:\n",
      "[816]\tvalid_0's l1: 0.0745994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  40%|####      | 8/20 [06:29<09:51, 49.30s/it]\u001b[32m[I 2021-06-06 10:06:27,043]\u001b[0m Trial 50 finished with value: 0.07459940996802569 and parameters: {'lambda_l1': 2.262335757569541, 'lambda_l2': 2.5073720079068798e-06}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  40%|####      | 8/20 [06:29<09:51, 49.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761403\n",
      "[400]\tvalid_0's l1: 0.0751783\n",
      "[600]\tvalid_0's l1: 0.0749339\n",
      "[800]\tvalid_0's l1: 0.0748154\n",
      "[1000]\tvalid_0's l1: 0.0747399\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[983]\tvalid_0's l1: 0.0747361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  45%|####5     | 9/20 [07:17<08:56, 48.82s/it]\u001b[32m[I 2021-06-06 10:07:14,799]\u001b[0m Trial 51 finished with value: 0.07473612666583954 and parameters: {'lambda_l1': 0.24434353193889144, 'lambda_l2': 1.3189893268776466e-08}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  45%|####5     | 9/20 [07:17<08:56, 48.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760565\n",
      "[400]\tvalid_0's l1: 0.0752347\n",
      "[600]\tvalid_0's l1: 0.0749942\n",
      "[800]\tvalid_0's l1: 0.0748549\n",
      "[1000]\tvalid_0's l1: 0.0747532\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0747526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  50%|#####     | 10/20 [08:01<07:54, 47.48s/it]\u001b[32m[I 2021-06-06 10:07:59,299]\u001b[0m Trial 52 finished with value: 0.07475256589697743 and parameters: {'lambda_l1': 0.002515127589391934, 'lambda_l2': 9.301930011653342e-05}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  50%|#####     | 10/20 [08:01<07:54, 47.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761382\n",
      "[400]\tvalid_0's l1: 0.0752438\n",
      "[600]\tvalid_0's l1: 0.0749515\n",
      "[800]\tvalid_0's l1: 0.0747352\n",
      "[1000]\tvalid_0's l1: 0.0746529\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0746521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  55%|#####5    | 11/20 [08:47<07:02, 46.92s/it]\u001b[32m[I 2021-06-06 10:08:44,937]\u001b[0m Trial 53 finished with value: 0.07465212047920716 and parameters: {'lambda_l1': 2.4098247167127857e-08, 'lambda_l2': 1.2911326373813542e-08}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  55%|#####5    | 11/20 [08:47<07:02, 46.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0759398\n",
      "[400]\tvalid_0's l1: 0.0747332\n",
      "[600]\tvalid_0's l1: 0.0744646\n",
      "[800]\tvalid_0's l1: 0.0743812\n",
      "Early stopping, best iteration is:\n",
      "[871]\tvalid_0's l1: 0.0743425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074311:  60%|######    | 12/20 [09:48<06:48, 51.11s/it]\u001b[32m[I 2021-06-06 10:09:45,646]\u001b[0m Trial 54 finished with value: 0.07434248426749626 and parameters: {'lambda_l1': 5.576042045734548, 'lambda_l2': 7.470755469623331e-07}. Best is trial 46 with value: 0.07431082760188162.\u001b[0m\n",
      "regularization_factors, val_score: 0.074311:  60%|######    | 12/20 [09:48<06:48, 51.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0759057\n",
      "[400]\tvalid_0's l1: 0.0747722\n",
      "[600]\tvalid_0's l1: 0.0744272\n",
      "[800]\tvalid_0's l1: 0.0743095\n",
      "Early stopping, best iteration is:\n",
      "[797]\tvalid_0's l1: 0.0743061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074306:  65%|######5   | 13/20 [10:44<06:08, 52.60s/it]\u001b[32m[I 2021-06-06 10:10:41,665]\u001b[0m Trial 55 finished with value: 0.07430605912320692 and parameters: {'lambda_l1': 4.94640168156492, 'lambda_l2': 2.3951042722899225e-07}. Best is trial 55 with value: 0.07430605912320692.\u001b[0m\n",
      "regularization_factors, val_score: 0.074306:  65%|######5   | 13/20 [10:44<06:08, 52.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0758925\n",
      "[400]\tvalid_0's l1: 0.0747966\n",
      "[600]\tvalid_0's l1: 0.0745797\n",
      "[800]\tvalid_0's l1: 0.0744947\n",
      "[1000]\tvalid_0's l1: 0.0744608\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[989]\tvalid_0's l1: 0.0744563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074306:  70%|#######   | 14/20 [11:47<05:35, 55.85s/it]\u001b[32m[I 2021-06-06 10:11:45,021]\u001b[0m Trial 56 finished with value: 0.07445634770568557 and parameters: {'lambda_l1': 4.322276558465661, 'lambda_l2': 9.012821628410277e-08}. Best is trial 55 with value: 0.07430605912320692.\u001b[0m\n",
      "regularization_factors, val_score: 0.074306:  70%|#######   | 14/20 [11:47<05:35, 55.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760136\n",
      "[400]\tvalid_0's l1: 0.0747242\n",
      "[600]\tvalid_0's l1: 0.0742701\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0741389\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's l1: 0.0740932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[992]\tvalid_0's l1: 0.0740927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074093:  75%|#######5  | 15/20 [12:50<04:49, 57.81s/it]\u001b[32m[I 2021-06-06 10:12:47,364]\u001b[0m Trial 57 finished with value: 0.07409266413073601 and parameters: {'lambda_l1': 9.623975862960359, 'lambda_l2': 1.3952194071618384e-07}. Best is trial 57 with value: 0.07409266413073601.\u001b[0m\n",
      "regularization_factors, val_score: 0.074093:  75%|#######5  | 15/20 [12:50<04:49, 57.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761815\n",
      "[400]\tvalid_0's l1: 0.0751638\n",
      "[600]\tvalid_0's l1: 0.074909\n",
      "[800]\tvalid_0's l1: 0.0747705\n",
      "[1000]\tvalid_0's l1: 0.0747181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0747181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074093:  80%|########  | 16/20 [13:40<03:42, 55.60s/it]\u001b[32m[I 2021-06-06 10:13:37,838]\u001b[0m Trial 58 finished with value: 0.07471814731006053 and parameters: {'lambda_l1': 0.42998481663477817, 'lambda_l2': 3.3889879334051525e-07}. Best is trial 57 with value: 0.07409266413073601.\u001b[0m\n",
      "regularization_factors, val_score: 0.074093:  80%|########  | 16/20 [13:40<03:42, 55.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761661\n",
      "[400]\tvalid_0's l1: 0.0751954\n",
      "[600]\tvalid_0's l1: 0.0749649\n",
      "[800]\tvalid_0's l1: 0.0748486\n",
      "[1000]\tvalid_0's l1: 0.0747511\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0747511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074093:  85%|########5 | 17/20 [14:33<02:44, 54.83s/it]\u001b[32m[I 2021-06-06 10:14:30,895]\u001b[0m Trial 59 finished with value: 0.07475105280537356 and parameters: {'lambda_l1': 2.0048984536990075e-07, 'lambda_l2': 0.002520980554422258}. Best is trial 57 with value: 0.07409266413073601.\u001b[0m\n",
      "regularization_factors, val_score: 0.074093:  85%|########5 | 17/20 [14:33<02:44, 54.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761419\n",
      "[400]\tvalid_0's l1: 0.0752058\n",
      "[600]\tvalid_0's l1: 0.07492\n",
      "[800]\tvalid_0's l1: 0.0747837\n",
      "[1000]\tvalid_0's l1: 0.0747374\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[994]\tvalid_0's l1: 0.0747359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074093:  90%|######### | 18/20 [15:19<01:44, 52.28s/it]\u001b[32m[I 2021-06-06 10:15:17,217]\u001b[0m Trial 60 finished with value: 0.07473585736470495 and parameters: {'lambda_l1': 0.018748404062414813, 'lambda_l2': 1.3952340310089512e-05}. Best is trial 57 with value: 0.07409266413073601.\u001b[0m\n",
      "regularization_factors, val_score: 0.074093:  90%|######### | 18/20 [15:19<01:44, 52.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0759355\n",
      "[400]\tvalid_0's l1: 0.0749803\n",
      "[600]\tvalid_0's l1: 0.0747624\n",
      "[800]\tvalid_0's l1: 0.0746413\n",
      "[1000]\tvalid_0's l1: 0.0746098\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's l1: 0.0745932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074093:  95%|#########5| 19/20 [16:15<00:53, 53.42s/it]\u001b[32m[I 2021-06-06 10:16:13,308]\u001b[0m Trial 61 finished with value: 0.0745932004688573 and parameters: {'lambda_l1': 0.7256637849460796, 'lambda_l2': 9.115647697878268e-08}. Best is trial 57 with value: 0.07409266413073601.\u001b[0m\n",
      "regularization_factors, val_score: 0.074093:  95%|#########5| 19/20 [16:15<00:53, 53.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761599\n",
      "[400]\tvalid_0's l1: 0.0752856\n",
      "[600]\tvalid_0's l1: 0.0750413\n",
      "[800]\tvalid_0's l1: 0.074891\n",
      "[1000]\tvalid_0's l1: 0.0747822\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0747822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074093: 100%|##########| 20/20 [17:00<00:00, 50.78s/it]\u001b[32m[I 2021-06-06 10:16:57,929]\u001b[0m Trial 62 finished with value: 0.07478222315230922 and parameters: {'lambda_l1': 0.003189429262780161, 'lambda_l2': 0.010277974525172361}. Best is trial 57 with value: 0.07409266413073601.\u001b[0m\n",
      "regularization_factors, val_score: 0.074093: 100%|##########| 20/20 [17:00<00:00, 51.03s/it]\n",
      "min_data_in_leaf, val_score: 0.074093:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760356\n",
      "[400]\tvalid_0's l1: 0.0746511\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0742037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0741098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's l1: 0.0740798\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's l1: 0.0740713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.074071:  20%|##        | 1/5 [01:04<04:19, 64.83s/it]\u001b[32m[I 2021-06-06 10:18:02,772]\u001b[0m Trial 63 finished with value: 0.0740712822634733 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.0740712822634733.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.074071:  20%|##        | 1/5 [01:04<04:19, 64.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760347\n",
      "[400]\tvalid_0's l1: 0.0746846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.074329\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0742063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1000]\tvalid_0's l1: 0.0741586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[948]\tvalid_0's l1: 0.0741582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.074071:  40%|####      | 2/5 [01:56<02:51, 57.11s/it]\u001b[32m[I 2021-06-06 10:18:54,478]\u001b[0m Trial 64 finished with value: 0.07415821584772418 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.0740712822634733.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.074071:  40%|####      | 2/5 [01:56<02:51, 57.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760535\n",
      "[400]\tvalid_0's l1: 0.0748075\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0743648\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0742226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's l1: 0.0741222\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0741208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.074071:  60%|######    | 3/5 [02:32<01:35, 47.66s/it]\u001b[32m[I 2021-06-06 10:19:30,882]\u001b[0m Trial 65 finished with value: 0.07412077747331758 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.0740712822634733.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.074071:  60%|######    | 3/5 [02:32<01:35, 47.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0759995\n",
      "[400]\tvalid_0's l1: 0.0746959\n",
      "[600]\tvalid_0's l1: 0.0743364\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0741845\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's l1: 0.0741141\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[989]\tvalid_0's l1: 0.0741136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.074071:  80%|########  | 4/5 [03:10<00:43, 43.70s/it]\u001b[32m[I 2021-06-06 10:20:08,509]\u001b[0m Trial 66 finished with value: 0.07411363241381047 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.0740712822634733.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.074071:  80%|########  | 4/5 [03:10<00:43, 43.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760616\n",
      "[400]\tvalid_0's l1: 0.0747438\n",
      "[600]\tvalid_0's l1: 0.0743374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0742211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's l1: 0.074157\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[925]\tvalid_0's l1: 0.0741437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.074071: 100%|##########| 5/5 [03:46<00:00, 40.84s/it]\u001b[32m[I 2021-06-06 10:20:44,292]\u001b[0m Trial 67 finished with value: 0.07414365279520477 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.0740712822634733.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.074071: 100%|##########| 5/5 [03:46<00:00, 45.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elaptedtime: 4240.418765306473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt_params = {\n",
    "    \"objective\":\"regression\",\n",
    "    \"metric\":\"mae\"\n",
    "}\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "opt=lgb.train(\n",
    "    opt_params,\n",
    "    trains,\n",
    "    valid_sets = valids,\n",
    "    verbose_eval=200,\n",
    "    num_boost_round = 1000,\n",
    "    early_stopping_rounds = 100,\n",
    ")\n",
    "end = time.time()\n",
    "print('elaptedtime:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "becoming-mirror",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12549\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 7.219784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0760356\n",
      "[400]\tvalid_0's l1: 0.0746511\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0742037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0741098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's l1: 0.0740798\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's l1: 0.0740713\n"
     ]
    }
   ],
   "source": [
    "# lightGBM\n",
    "import lightgbm as lgb\n",
    "best_params = opt.params\n",
    "model = lgb.train(best_params, trains, valid_sets=valids, num_boost_round=1000, early_stopping_rounds=100, verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "future-control",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07407128453283864"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = model.predict(val_x)\n",
    "mae(vals, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "twelve-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>地区名</th>\n",
       "      <td>17342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>最寄駅：名称</th>\n",
       "      <td>15455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>市区町村名</th>\n",
       "      <td>8996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>建築年</th>\n",
       "      <td>3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>取引時点</th>\n",
       "      <td>3463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>面積（㎡）</th>\n",
       "      <td>2572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>間取り</th>\n",
       "      <td>2086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>最寄駅：距離（分）</th>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>都市計画</th>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>都道府県名</th>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>容積率（％）</th>\n",
       "      <td>1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平均価格</th>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>緯度</th>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>経度</th>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>建物の構造</th>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>改装</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今後の利用目的</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>取引の事情等</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用途</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>建ぺい率（％）</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           importance\n",
       "地区名             17342\n",
       "最寄駅：名称          15455\n",
       "市区町村名            8996\n",
       "建築年              3700\n",
       "取引時点             3463\n",
       "面積（㎡）            2572\n",
       "間取り              2086\n",
       "最寄駅：距離（分）        1985\n",
       "都市計画             1922\n",
       "都道府県名            1893\n",
       "容積率（％）           1342\n",
       "平均価格              706\n",
       "緯度                696\n",
       "経度                637\n",
       "建物の構造             407\n",
       "改装                364\n",
       "今後の利用目的           362\n",
       "取引の事情等            278\n",
       "用途                225\n",
       "建ぺい率（％）           160"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model.feature_importance(), index=val_x.columns, columns=[\"importance\"]).sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "composite-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(df_test)\n",
    "df_test[\"取引価格（総額）_log\"] = predict\n",
    "df_test[[\"取引価格（総額）_log\"]].to_csv(\"./output/15_sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "congressional-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>都道府県名</th>\n",
       "      <th>市区町村名</th>\n",
       "      <th>地区名</th>\n",
       "      <th>最寄駅：名称</th>\n",
       "      <th>最寄駅：距離（分）</th>\n",
       "      <th>間取り</th>\n",
       "      <th>面積（㎡）</th>\n",
       "      <th>建築年</th>\n",
       "      <th>建物の構造</th>\n",
       "      <th>用途</th>\n",
       "      <th>...</th>\n",
       "      <th>建ぺい率（％）</th>\n",
       "      <th>容積率（％）</th>\n",
       "      <th>取引時点</th>\n",
       "      <th>改装</th>\n",
       "      <th>取引の事情等</th>\n",
       "      <th>取引価格（総額）_log</th>\n",
       "      <th>緯度</th>\n",
       "      <th>経度</th>\n",
       "      <th>クラスタ平均</th>\n",
       "      <th>平均価格</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>新中野町</td>\n",
       "      <td>苫小牧</td>\n",
       "      <td>25.0</td>\n",
       "      <td>３ＬＤＫ</td>\n",
       "      <td>120.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2018.75</td>\n",
       "      <td>未改装</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.431364</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>青葉町</td>\n",
       "      <td>青葉</td>\n",
       "      <td>9.0</td>\n",
       "      <td>３ＬＤＫ</td>\n",
       "      <td>70.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2017.75</td>\n",
       "      <td>未改装</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.342423</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>青葉町</td>\n",
       "      <td>青葉</td>\n",
       "      <td>3.0</td>\n",
       "      <td>３ＬＤＫ</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2016.50</td>\n",
       "      <td>改装済</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.778151</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>表町</td>\n",
       "      <td>苫小牧</td>\n",
       "      <td>8.0</td>\n",
       "      <td>４ＬＤＫ</td>\n",
       "      <td>105.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2011.99</td>\n",
       "      <td>未改装</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.230449</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>新中野町</td>\n",
       "      <td>苫小牧</td>\n",
       "      <td>25.0</td>\n",
       "      <td>３ＬＤＫ</td>\n",
       "      <td>90.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2015.50</td>\n",
       "      <td>未改装</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.204120</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  都道府県名 市区町村名   地区名 最寄駅：名称  最寄駅：距離（分）   間取り  面積（㎡）   建築年 建物の構造  用途  ...  \\\n",
       "0   北海道  苫小牧市  新中野町    苫小牧       25.0  ３ＬＤＫ  120.0  12.0    ＲＣ  住宅  ...   \n",
       "1   北海道  苫小牧市   青葉町     青葉        9.0  ３ＬＤＫ   70.0  35.0    ＲＣ  住宅  ...   \n",
       "2   北海道  苫小牧市   青葉町     青葉        3.0  ３ＬＤＫ   70.0  31.0    ＲＣ  住宅  ...   \n",
       "3   北海道  苫小牧市    表町    苫小牧        8.0  ４ＬＤＫ  105.0  18.0    ＲＣ  住宅  ...   \n",
       "4   北海道  苫小牧市  新中野町    苫小牧       25.0  ３ＬＤＫ   90.0  15.0    ＲＣ  住宅  ...   \n",
       "\n",
       "  建ぺい率（％） 容積率（％）     取引時点   改装  取引の事情等 取引価格（総額）_log         緯度          経度  \\\n",
       "0    60.0  200.0  2018.75  未改装     NaN     7.431364  42.631246  141.603122   \n",
       "1    60.0  200.0  2017.75  未改装     NaN     6.342423  42.631246  141.603122   \n",
       "2    60.0  200.0  2016.50  改装済     NaN     6.778151  42.631246  141.603122   \n",
       "3    80.0  400.0  2011.99  未改装     NaN     7.230449  42.631246  141.603122   \n",
       "4    60.0  200.0  2015.50  未改装     NaN     7.204120  42.631246  141.603122   \n",
       "\n",
       "   クラスタ平均      平均価格  \n",
       "0     2.0  0.092308  \n",
       "1     2.0  0.092308  \n",
       "2     2.0  0.092308  \n",
       "3     2.0  0.092308  \n",
       "4     2.0  0.092308  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-transparency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
