{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "significant-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre7 import data_pre\n",
    "from input_data import input_df\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "synthetic-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "df = input_df()\n",
    "df = data_pre(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "specialized-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/tmp/working/dataset/nishika/old_apartment_2020/test.csv\", index_col=0)\n",
    "\n",
    "df_test = data_pre(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unable-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"間取り\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "underlying-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(\"間取り\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bright-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold,cross_validate\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import lightgbm\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.2)\n",
    "\n",
    "col = \"取引価格（総額）_log\"\n",
    "train_y = df_train[col]\n",
    "train_x = df_train.drop(col, axis=1)\n",
    "\n",
    "val_y = df_val[col]\n",
    "val_x = df_val.drop(col, axis=1)\n",
    "\n",
    "trains = lgb.Dataset(train_x, train_y)\n",
    "valids = lgb.Dataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beginning-cooperation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 12:54:59,913]\u001b[0m A new study created in memory with name: no-name-999ef7ec-20d7-42fb-bbb9-25e496686762\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's l1: 0.0779924\n",
      "[400]\tvalid_0's l1: 0.0763681\n",
      "[600]\tvalid_0's l1: 0.0758235\n",
      "[800]\tvalid_0's l1: 0.0755315\n",
      "[1000]\tvalid_0's l1: 0.075334\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0753339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075334:  14%|#4        | 1/7 [00:32<03:16, 32.79s/it]\u001b[32m[I 2021-06-09 12:55:32,709]\u001b[0m Trial 0 finished with value: 0.07533390594540722 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.07533390594540722.\u001b[0m\n",
      "feature_fraction, val_score: 0.075334:  14%|#4        | 1/7 [00:32<03:16, 32.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0782222\n",
      "[400]\tvalid_0's l1: 0.0766454\n",
      "[600]\tvalid_0's l1: 0.0761879\n",
      "[800]\tvalid_0's l1: 0.075964\n",
      "[1000]\tvalid_0's l1: 0.0758112\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's l1: 0.0758104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075334:  29%|##8       | 2/7 [01:20<03:26, 41.31s/it]\u001b[32m[I 2021-06-09 12:56:19,991]\u001b[0m Trial 1 finished with value: 0.07581042643324035 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.07533390594540722.\u001b[0m\n",
      "feature_fraction, val_score: 0.075334:  29%|##8       | 2/7 [01:20<03:26, 41.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0777961\n",
      "[400]\tvalid_0's l1: 0.0761193\n",
      "[600]\tvalid_0's l1: 0.075529\n",
      "[800]\tvalid_0's l1: 0.0751619\n",
      "[1000]\tvalid_0's l1: 0.0750063\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0750063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075006:  43%|####2     | 3/7 [01:50<02:26, 36.55s/it]\u001b[32m[I 2021-06-09 12:56:50,876]\u001b[0m Trial 2 finished with value: 0.0750063146187039 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.0750063146187039.\u001b[0m\n",
      "feature_fraction, val_score: 0.075006:  43%|####2     | 3/7 [01:50<02:26, 36.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0781252\n",
      "[400]\tvalid_0's l1: 0.0766169\n",
      "[600]\tvalid_0's l1: 0.0761511\n",
      "[800]\tvalid_0's l1: 0.0759483\n",
      "[1000]\tvalid_0's l1: 0.0757073\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\tvalid_0's l1: 0.075707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075006:  57%|#####7    | 4/7 [02:28<01:50, 36.90s/it]\u001b[32m[I 2021-06-09 12:57:28,302]\u001b[0m Trial 3 finished with value: 0.075706955874612 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.0750063146187039.\u001b[0m\n",
      "feature_fraction, val_score: 0.075006:  57%|#####7    | 4/7 [02:28<01:50, 36.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0779993\n",
      "[400]\tvalid_0's l1: 0.0761993\n",
      "[600]\tvalid_0's l1: 0.0755462\n",
      "[800]\tvalid_0's l1: 0.0752054\n",
      "[1000]\tvalid_0's l1: 0.0750288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0750288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075006:  71%|#######1  | 5/7 [02:54<01:06, 33.16s/it]\u001b[32m[I 2021-06-09 12:57:54,826]\u001b[0m Trial 4 finished with value: 0.07502881373533875 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.0750063146187039.\u001b[0m\n",
      "feature_fraction, val_score: 0.075006:  71%|#######1  | 5/7 [02:54<01:06, 33.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0777575\n",
      "[400]\tvalid_0's l1: 0.0761608\n",
      "[600]\tvalid_0's l1: 0.0755988\n",
      "[800]\tvalid_0's l1: 0.0753003\n",
      "[1000]\tvalid_0's l1: 0.0751693\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0751693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075006:  86%|########5 | 6/7 [03:30<00:33, 33.95s/it]\u001b[32m[I 2021-06-09 12:58:30,310]\u001b[0m Trial 5 finished with value: 0.07516934057303709 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.0750063146187039.\u001b[0m\n",
      "feature_fraction, val_score: 0.075006:  86%|########5 | 6/7 [03:30<00:33, 33.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0780161\n",
      "[400]\tvalid_0's l1: 0.0764853\n",
      "[600]\tvalid_0's l1: 0.0760057\n",
      "[800]\tvalid_0's l1: 0.0757361\n",
      "[1000]\tvalid_0's l1: 0.0756067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0756067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.075006: 100%|##########| 7/7 [04:09<00:00, 35.68s/it]\u001b[32m[I 2021-06-09 12:59:09,556]\u001b[0m Trial 6 finished with value: 0.07560666835667416 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.0750063146187039.\u001b[0m\n",
      "feature_fraction, val_score: 0.075006: 100%|##########| 7/7 [04:09<00:00, 35.66s/it]\n",
      "num_leaves, val_score: 0.075006:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.075008\n",
      "[400]\tvalid_0's l1: 0.0745244\n",
      "Early stopping, best iteration is:\n",
      "[494]\tvalid_0's l1: 0.0744469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074447:   5%|5         | 1/20 [00:39<12:37, 39.89s/it]\u001b[32m[I 2021-06-09 12:59:49,456]\u001b[0m Trial 7 finished with value: 0.07444694161689928 and parameters: {'num_leaves': 129}. Best is trial 7 with value: 0.07444694161689928.\u001b[0m\n",
      "num_leaves, val_score: 0.074447:   5%|5         | 1/20 [00:39<12:37, 39.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751141\n",
      "[400]\tvalid_0's l1: 0.074603\n",
      "[600]\tvalid_0's l1: 0.0744273\n",
      "[800]\tvalid_0's l1: 0.0743798\n",
      "Early stopping, best iteration is:\n",
      "[865]\tvalid_0's l1: 0.0743504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074350:  10%|#         | 2/20 [01:27<13:15, 44.21s/it]\u001b[32m[I 2021-06-09 13:00:36,679]\u001b[0m Trial 8 finished with value: 0.07435043565027219 and parameters: {'num_leaves': 114}. Best is trial 8 with value: 0.07435043565027219.\u001b[0m\n",
      "num_leaves, val_score: 0.074350:  10%|#         | 2/20 [01:27<13:15, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0749295\n",
      "[400]\tvalid_0's l1: 0.0745668\n",
      "[600]\tvalid_0's l1: 0.0744631\n",
      "[800]\tvalid_0's l1: 0.0744142\n",
      "Early stopping, best iteration is:\n",
      "[825]\tvalid_0's l1: 0.0744066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074350:  15%|#5        | 3/20 [02:16<13:13, 46.69s/it]\u001b[32m[I 2021-06-09 13:01:26,333]\u001b[0m Trial 9 finished with value: 0.07440663135840946 and parameters: {'num_leaves': 136}. Best is trial 8 with value: 0.07435043565027219.\u001b[0m\n",
      "num_leaves, val_score: 0.074350:  15%|#5        | 3/20 [02:16<13:13, 46.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0786889\n",
      "[400]\tvalid_0's l1: 0.076596\n",
      "[600]\tvalid_0's l1: 0.0758586\n",
      "[800]\tvalid_0's l1: 0.0755183\n",
      "[1000]\tvalid_0's l1: 0.0753397\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0753397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074350:  20%|##        | 4/20 [02:47<10:46, 40.40s/it]\u001b[32m[I 2021-06-09 13:01:57,079]\u001b[0m Trial 10 finished with value: 0.07533973261300189 and parameters: {'num_leaves': 25}. Best is trial 8 with value: 0.07435043565027219.\u001b[0m\n",
      "num_leaves, val_score: 0.074350:  20%|##        | 4/20 [02:47<10:46, 40.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0755115\n",
      "[400]\tvalid_0's l1: 0.0747986\n",
      "[600]\tvalid_0's l1: 0.07454\n",
      "[800]\tvalid_0's l1: 0.0744181\n",
      "[1000]\tvalid_0's l1: 0.0743915\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[974]\tvalid_0's l1: 0.0743913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074350:  25%|##5       | 5/20 [03:34<10:42, 42.83s/it]\u001b[32m[I 2021-06-09 13:02:44,235]\u001b[0m Trial 11 finished with value: 0.07439125552582308 and parameters: {'num_leaves': 82}. Best is trial 8 with value: 0.07435043565027219.\u001b[0m\n",
      "num_leaves, val_score: 0.074350:  25%|##5       | 5/20 [03:34<10:42, 42.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0748833\n",
      "[400]\tvalid_0's l1: 0.0745293\n",
      "[600]\tvalid_0's l1: 0.0744132\n",
      "[800]\tvalid_0's l1: 0.0743947\n",
      "Early stopping, best iteration is:\n",
      "[847]\tvalid_0's l1: 0.0743786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074350:  30%|###       | 6/20 [04:27<10:47, 46.23s/it]\u001b[32m[I 2021-06-09 13:03:37,045]\u001b[0m Trial 12 finished with value: 0.07437862507954722 and parameters: {'num_leaves': 145}. Best is trial 8 with value: 0.07435043565027219.\u001b[0m\n",
      "num_leaves, val_score: 0.074350:  30%|###       | 6/20 [04:27<10:47, 46.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752343\n",
      "[400]\tvalid_0's l1: 0.0746644\n",
      "[600]\tvalid_0's l1: 0.0744551\n",
      "[800]\tvalid_0's l1: 0.0744012\n",
      "[1000]\tvalid_0's l1: 0.0744021\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[902]\tvalid_0's l1: 0.0743908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074350:  35%|###5      | 7/20 [05:14<10:04, 46.47s/it]\u001b[32m[I 2021-06-09 13:04:24,006]\u001b[0m Trial 13 finished with value: 0.07439082329635345 and parameters: {'num_leaves': 92}. Best is trial 8 with value: 0.07435043565027219.\u001b[0m\n",
      "num_leaves, val_score: 0.074350:  35%|###5      | 7/20 [05:14<10:04, 46.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0746977\n",
      "[400]\tvalid_0's l1: 0.074497\n",
      "Early stopping, best iteration is:\n",
      "[495]\tvalid_0's l1: 0.0744428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074350:  40%|####      | 8/20 [06:04<09:32, 47.68s/it]\u001b[32m[I 2021-06-09 13:05:14,272]\u001b[0m Trial 14 finished with value: 0.07444284234008315 and parameters: {'num_leaves': 209}. Best is trial 8 with value: 0.07435043565027219.\u001b[0m\n",
      "num_leaves, val_score: 0.074350:  40%|####      | 8/20 [06:04<09:32, 47.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0747567\n",
      "[400]\tvalid_0's l1: 0.0745103\n",
      "Early stopping, best iteration is:\n",
      "[366]\tvalid_0's l1: 0.0744859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074350:  45%|####5     | 9/20 [06:46<08:24, 45.87s/it]\u001b[32m[I 2021-06-09 13:05:56,168]\u001b[0m Trial 15 finished with value: 0.07448591608439123 and parameters: {'num_leaves': 189}. Best is trial 8 with value: 0.07435043565027219.\u001b[0m\n",
      "num_leaves, val_score: 0.074350:  45%|####5     | 9/20 [06:46<08:24, 45.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0754677\n",
      "[400]\tvalid_0's l1: 0.0747268\n",
      "[600]\tvalid_0's l1: 0.0745008\n",
      "[800]\tvalid_0's l1: 0.0744066\n",
      "[1000]\tvalid_0's l1: 0.0743202\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[989]\tvalid_0's l1: 0.0743172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074317:  50%|#####     | 10/20 [07:30<07:33, 45.38s/it]\u001b[32m[I 2021-06-09 13:06:40,454]\u001b[0m Trial 16 finished with value: 0.07431721514800783 and parameters: {'num_leaves': 78}. Best is trial 16 with value: 0.07431721514800783.\u001b[0m\n",
      "num_leaves, val_score: 0.074317:  50%|#####     | 10/20 [07:30<07:33, 45.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.101395\n",
      "[400]\tvalid_0's l1: 0.0933621\n",
      "[600]\tvalid_0's l1: 0.0899239\n",
      "[800]\tvalid_0's l1: 0.0878331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074317:  55%|#####5    | 11/20 [07:47<05:29, 36.61s/it]\u001b[32m[I 2021-06-09 13:06:57,169]\u001b[0m Trial 17 finished with value: 0.08645804917100022 and parameters: {'num_leaves': 3}. Best is trial 16 with value: 0.07431721514800783.\u001b[0m\n",
      "num_leaves, val_score: 0.074317:  55%|#####5    | 11/20 [07:47<05:29, 36.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's l1: 0.086458\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.086458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0761088\n",
      "[400]\tvalid_0's l1: 0.0750753\n",
      "[600]\tvalid_0's l1: 0.07475\n",
      "[800]\tvalid_0's l1: 0.0745546\n",
      "[1000]\tvalid_0's l1: 0.074477\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\tvalid_0's l1: 0.0744759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074317:  60%|######    | 12/20 [08:26<04:59, 37.40s/it]\u001b[32m[I 2021-06-09 13:07:36,381]\u001b[0m Trial 18 finished with value: 0.07447590182325416 and parameters: {'num_leaves': 56}. Best is trial 16 with value: 0.07431721514800783.\u001b[0m\n",
      "num_leaves, val_score: 0.074317:  60%|######    | 12/20 [08:26<04:59, 37.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753403\n",
      "[400]\tvalid_0's l1: 0.0746456\n",
      "[600]\tvalid_0's l1: 0.0744639\n",
      "[800]\tvalid_0's l1: 0.0743617\n",
      "[1000]\tvalid_0's l1: 0.0743115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0743101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074310:  65%|######5   | 13/20 [09:10<04:35, 39.40s/it]\u001b[32m[I 2021-06-09 13:08:20,383]\u001b[0m Trial 19 finished with value: 0.07431009298773159 and parameters: {'num_leaves': 89}. Best is trial 19 with value: 0.07431009298773159.\u001b[0m\n",
      "num_leaves, val_score: 0.074310:  65%|######5   | 13/20 [09:10<04:35, 39.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0767551\n",
      "[400]\tvalid_0's l1: 0.0754517\n",
      "[600]\tvalid_0's l1: 0.0750364\n",
      "[800]\tvalid_0's l1: 0.0748441\n",
      "[1000]\tvalid_0's l1: 0.0746934\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0746933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074310:  70%|#######   | 14/20 [09:45<03:47, 37.99s/it]\u001b[32m[I 2021-06-09 13:08:55,121]\u001b[0m Trial 20 finished with value: 0.07469333026752427 and parameters: {'num_leaves': 44}. Best is trial 19 with value: 0.07431009298773159.\u001b[0m\n",
      "num_leaves, val_score: 0.074310:  70%|#######   | 14/20 [09:45<03:47, 37.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.075389\n",
      "[400]\tvalid_0's l1: 0.0747308\n",
      "[600]\tvalid_0's l1: 0.0745377\n",
      "[800]\tvalid_0's l1: 0.0744138\n",
      "[1000]\tvalid_0's l1: 0.0743926\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0743915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074310:  75%|#######5  | 15/20 [10:33<03:24, 40.98s/it]\u001b[32m[I 2021-06-09 13:09:43,014]\u001b[0m Trial 21 finished with value: 0.07439149332794846 and parameters: {'num_leaves': 88}. Best is trial 19 with value: 0.07431009298773159.\u001b[0m\n",
      "num_leaves, val_score: 0.074310:  75%|#######5  | 15/20 [10:33<03:24, 40.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0747898\n",
      "[400]\tvalid_0's l1: 0.0745106\n",
      "[600]\tvalid_0's l1: 0.0744298\n",
      "Early stopping, best iteration is:\n",
      "[631]\tvalid_0's l1: 0.0744229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074310:  80%|########  | 16/20 [11:22<02:53, 43.37s/it]\u001b[32m[I 2021-06-09 13:10:31,929]\u001b[0m Trial 22 finished with value: 0.0744229049740583 and parameters: {'num_leaves': 167}. Best is trial 19 with value: 0.07431009298773159.\u001b[0m\n",
      "num_leaves, val_score: 0.074310:  80%|########  | 16/20 [11:22<02:53, 43.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0746611\n",
      "[400]\tvalid_0's l1: 0.0745203\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's l1: 0.0744879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074310:  85%|########5 | 17/20 [12:02<02:07, 42.45s/it]\u001b[32m[I 2021-06-09 13:11:12,258]\u001b[0m Trial 23 finished with value: 0.07448790564537522 and parameters: {'num_leaves': 249}. Best is trial 19 with value: 0.07431009298773159.\u001b[0m\n",
      "num_leaves, val_score: 0.074310:  85%|########5 | 17/20 [12:02<02:07, 42.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0759366\n",
      "[400]\tvalid_0's l1: 0.0750313\n",
      "[600]\tvalid_0's l1: 0.0746692\n",
      "[800]\tvalid_0's l1: 0.0745535\n",
      "[1000]\tvalid_0's l1: 0.0744485\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0744485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074310:  90%|######### | 18/20 [12:40<01:22, 41.05s/it]\u001b[32m[I 2021-06-09 13:11:50,043]\u001b[0m Trial 24 finished with value: 0.07444854014901689 and parameters: {'num_leaves': 60}. Best is trial 19 with value: 0.07431009298773159.\u001b[0m\n",
      "num_leaves, val_score: 0.074310:  90%|######### | 18/20 [12:40<01:22, 41.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0830886\n",
      "[400]\tvalid_0's l1: 0.0796937\n",
      "[600]\tvalid_0's l1: 0.0782138\n",
      "[800]\tvalid_0's l1: 0.0775072\n",
      "[1000]\tvalid_0's l1: 0.0770874\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0770874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074310:  95%|#########5| 19/20 [13:07<00:36, 36.71s/it]\u001b[32m[I 2021-06-09 13:12:16,641]\u001b[0m Trial 25 finished with value: 0.07708743658060177 and parameters: {'num_leaves': 12}. Best is trial 19 with value: 0.07431009298773159.\u001b[0m\n",
      "num_leaves, val_score: 0.074310:  95%|#########5| 19/20 [13:07<00:36, 36.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751141\n",
      "[400]\tvalid_0's l1: 0.074603\n",
      "[600]\tvalid_0's l1: 0.0744273\n",
      "[800]\tvalid_0's l1: 0.0743798\n",
      "Early stopping, best iteration is:\n",
      "[865]\tvalid_0's l1: 0.0743504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.074310: 100%|##########| 20/20 [13:48<00:00, 38.21s/it]\u001b[32m[I 2021-06-09 13:12:58,344]\u001b[0m Trial 26 finished with value: 0.07435043565027219 and parameters: {'num_leaves': 114}. Best is trial 19 with value: 0.07431009298773159.\u001b[0m\n",
      "num_leaves, val_score: 0.074310: 100%|##########| 20/20 [13:48<00:00, 41.44s/it]\n",
      "bagging, val_score: 0.074310:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0754676\n",
      "[400]\tvalid_0's l1: 0.0748838\n",
      "[600]\tvalid_0's l1: 0.0746729\n",
      "[800]\tvalid_0's l1: 0.0746161\n",
      "[1000]\tvalid_0's l1: 0.0745615\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's l1: 0.0745603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  10%|#         | 1/10 [00:46<07:00, 46.72s/it]\u001b[32m[I 2021-06-09 13:13:45,068]\u001b[0m Trial 27 finished with value: 0.07456031011107243 and parameters: {'bagging_fraction': 0.9938099136098454, 'bagging_freq': 7}. Best is trial 27 with value: 0.07456031011107243.\u001b[0m\n",
      "bagging, val_score: 0.074310:  10%|#         | 1/10 [00:46<07:00, 46.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0765809\n",
      "[400]\tvalid_0's l1: 0.076077\n",
      "[600]\tvalid_0's l1: 0.0757811\n",
      "Early stopping, best iteration is:\n",
      "[624]\tvalid_0's l1: 0.0757406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  20%|##        | 2/10 [02:06<08:49, 66.14s/it]\u001b[32m[I 2021-06-09 13:15:04,800]\u001b[0m Trial 28 finished with value: 0.07574064022996475 and parameters: {'bagging_fraction': 0.5984246085167054, 'bagging_freq': 7}. Best is trial 27 with value: 0.07456031011107243.\u001b[0m\n",
      "bagging, val_score: 0.074310:  20%|##        | 2/10 [02:06<08:49, 66.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0765718\n",
      "[400]\tvalid_0's l1: 0.0760415\n",
      "[600]\tvalid_0's l1: 0.0757716\n",
      "[800]\tvalid_0's l1: 0.0756225\n",
      "Early stopping, best iteration is:\n",
      "[841]\tvalid_0's l1: 0.0755623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  30%|###       | 3/10 [03:54<09:56, 85.19s/it]\u001b[32m[I 2021-06-09 13:16:52,652]\u001b[0m Trial 29 finished with value: 0.07556230475024733 and parameters: {'bagging_fraction': 0.5750830534625909, 'bagging_freq': 4}. Best is trial 27 with value: 0.07456031011107243.\u001b[0m\n",
      "bagging, val_score: 0.074310:  30%|###       | 3/10 [03:54<09:56, 85.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0765498\n",
      "[400]\tvalid_0's l1: 0.0759995\n",
      "[600]\tvalid_0's l1: 0.0757135\n",
      "[800]\tvalid_0's l1: 0.0755273\n",
      "[1000]\tvalid_0's l1: 0.0754856\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[986]\tvalid_0's l1: 0.075446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  40%|####      | 4/10 [05:52<09:50, 98.37s/it]\u001b[32m[I 2021-06-09 13:18:51,227]\u001b[0m Trial 30 finished with value: 0.07544598819295287 and parameters: {'bagging_fraction': 0.5891498473179454, 'bagging_freq': 3}. Best is trial 27 with value: 0.07456031011107243.\u001b[0m\n",
      "bagging, val_score: 0.074310:  40%|####      | 4/10 [05:52<09:50, 98.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0759067\n",
      "[400]\tvalid_0's l1: 0.0753424\n",
      "[600]\tvalid_0's l1: 0.0750832\n",
      "[800]\tvalid_0's l1: 0.0749204\n",
      "Early stopping, best iteration is:\n",
      "[795]\tvalid_0's l1: 0.0749101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  50%|#####     | 5/10 [07:29<08:09, 97.84s/it]\u001b[32m[I 2021-06-09 13:20:28,123]\u001b[0m Trial 31 finished with value: 0.07491009498055386 and parameters: {'bagging_fraction': 0.7438862892410432, 'bagging_freq': 7}. Best is trial 27 with value: 0.07456031011107243.\u001b[0m\n",
      "bagging, val_score: 0.074310:  50%|#####     | 5/10 [07:29<08:09, 97.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0763536\n",
      "[400]\tvalid_0's l1: 0.075726\n",
      "[600]\tvalid_0's l1: 0.0754658\n",
      "[800]\tvalid_0's l1: 0.0753089\n",
      "[1000]\tvalid_0's l1: 0.0752265\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[982]\tvalid_0's l1: 0.0752198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  60%|######    | 6/10 [09:02<06:23, 95.94s/it]\u001b[32m[I 2021-06-09 13:22:00,389]\u001b[0m Trial 32 finished with value: 0.07521978107910936 and parameters: {'bagging_fraction': 0.6292470859802907, 'bagging_freq': 1}. Best is trial 27 with value: 0.07456031011107243.\u001b[0m\n",
      "bagging, val_score: 0.074310:  60%|######    | 6/10 [09:02<06:23, 95.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.076382\n",
      "[400]\tvalid_0's l1: 0.0758514\n",
      "[600]\tvalid_0's l1: 0.0755582\n",
      "[800]\tvalid_0's l1: 0.0753977\n",
      "[1000]\tvalid_0's l1: 0.0754292\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[946]\tvalid_0's l1: 0.075356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  70%|#######   | 7/10 [10:58<05:07, 102.50s/it]\u001b[32m[I 2021-06-09 13:23:56,376]\u001b[0m Trial 33 finished with value: 0.07535603640583642 and parameters: {'bagging_fraction': 0.6201454525006744, 'bagging_freq': 5}. Best is trial 27 with value: 0.07456031011107243.\u001b[0m\n",
      "bagging, val_score: 0.074310:  70%|#######   | 7/10 [10:58<05:07, 102.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0754573\n",
      "[400]\tvalid_0's l1: 0.0748804\n",
      "[600]\tvalid_0's l1: 0.0746394\n",
      "[800]\tvalid_0's l1: 0.0745251\n",
      "Early stopping, best iteration is:\n",
      "[899]\tvalid_0's l1: 0.074471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  80%|########  | 8/10 [12:11<03:06, 93.25s/it] \u001b[32m[I 2021-06-09 13:25:09,819]\u001b[0m Trial 34 finished with value: 0.07447101108323328 and parameters: {'bagging_fraction': 0.9464869659689389, 'bagging_freq': 4}. Best is trial 34 with value: 0.07447101108323328.\u001b[0m\n",
      "bagging, val_score: 0.074310:  80%|########  | 8/10 [12:11<03:06, 93.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.076162\n",
      "[400]\tvalid_0's l1: 0.0755829\n",
      "[600]\tvalid_0's l1: 0.0753076\n",
      "[800]\tvalid_0's l1: 0.0751703\n",
      "[1000]\tvalid_0's l1: 0.075141\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[958]\tvalid_0's l1: 0.0751109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310:  90%|######### | 9/10 [14:10<01:41, 101.17s/it]\u001b[32m[I 2021-06-09 13:27:08,426]\u001b[0m Trial 35 finished with value: 0.07511086193122232 and parameters: {'bagging_fraction': 0.6794167163456233, 'bagging_freq': 2}. Best is trial 34 with value: 0.07447101108323328.\u001b[0m\n",
      "bagging, val_score: 0.074310:  90%|######### | 9/10 [14:10<01:41, 101.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.076435\n",
      "[400]\tvalid_0's l1: 0.0759426\n",
      "[600]\tvalid_0's l1: 0.0757045\n",
      "[800]\tvalid_0's l1: 0.0755848\n",
      "[1000]\tvalid_0's l1: 0.075545\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[949]\tvalid_0's l1: 0.0754947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.074310: 100%|##########| 10/10 [16:01<00:00, 104.32s/it]\u001b[32m[I 2021-06-09 13:28:59,797]\u001b[0m Trial 36 finished with value: 0.07549466980207893 and parameters: {'bagging_fraction': 0.6072188978317673, 'bagging_freq': 6}. Best is trial 34 with value: 0.07447101108323328.\u001b[0m\n",
      "bagging, val_score: 0.074310: 100%|##########| 10/10 [16:01<00:00, 96.14s/it] \n",
      "feature_fraction_stage2, val_score: 0.074310:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0756711\n",
      "[400]\tvalid_0's l1: 0.0748286\n",
      "[600]\tvalid_0's l1: 0.0745952\n",
      "[800]\tvalid_0's l1: 0.0744743\n",
      "[1000]\tvalid_0's l1: 0.0743977\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's l1: 0.0743976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074310:  17%|#6        | 1/6 [00:27<02:18, 27.73s/it]\u001b[32m[I 2021-06-09 13:29:27,533]\u001b[0m Trial 37 finished with value: 0.07439761052985079 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.07439761052985079.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074310:  17%|#6        | 1/6 [00:27<02:18, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753403\n",
      "[400]\tvalid_0's l1: 0.0746456\n",
      "[600]\tvalid_0's l1: 0.0744639\n",
      "[800]\tvalid_0's l1: 0.0743617\n",
      "[1000]\tvalid_0's l1: 0.0743115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0743101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074310:  33%|###3      | 2/6 [00:57<01:56, 29.10s/it]\u001b[32m[I 2021-06-09 13:29:57,586]\u001b[0m Trial 38 finished with value: 0.07431009298773159 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 38 with value: 0.07431009298773159.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074310:  33%|###3      | 2/6 [00:57<01:56, 29.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0755774\n",
      "[400]\tvalid_0's l1: 0.0748851\n",
      "[600]\tvalid_0's l1: 0.074689\n",
      "[800]\tvalid_0's l1: 0.0745901\n",
      "[1000]\tvalid_0's l1: 0.07453\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.07453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074310:  50%|#####     | 3/6 [01:25<01:25, 28.53s/it]\u001b[32m[I 2021-06-09 13:30:25,447]\u001b[0m Trial 39 finished with value: 0.07453001651763771 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 38 with value: 0.07431009298773159.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074310:  50%|#####     | 3/6 [01:25<01:25, 28.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753403\n",
      "[400]\tvalid_0's l1: 0.0746456\n",
      "[600]\tvalid_0's l1: 0.0744639\n",
      "[800]\tvalid_0's l1: 0.0743617\n",
      "[1000]\tvalid_0's l1: 0.0743115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0743101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074310:  67%|######6   | 4/6 [02:07<01:07, 33.70s/it]\u001b[32m[I 2021-06-09 13:31:07,078]\u001b[0m Trial 40 finished with value: 0.07431009298773159 and parameters: {'feature_fraction': 0.516}. Best is trial 38 with value: 0.07431009298773159.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074310:  67%|######6   | 4/6 [02:07<01:07, 33.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0755774\n",
      "[400]\tvalid_0's l1: 0.0748851\n",
      "[600]\tvalid_0's l1: 0.074689\n",
      "[800]\tvalid_0's l1: 0.0745901\n",
      "[1000]\tvalid_0's l1: 0.0745301\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 0.0745301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074310:  83%|########3 | 5/6 [02:53<00:38, 38.30s/it]\u001b[32m[I 2021-06-09 13:31:53,542]\u001b[0m Trial 41 finished with value: 0.07453006717816026 and parameters: {'feature_fraction': 0.484}. Best is trial 38 with value: 0.07431009298773159.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074310:  83%|########3 | 5/6 [02:53<00:38, 38.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751789\n",
      "[400]\tvalid_0's l1: 0.0746299\n",
      "[600]\tvalid_0's l1: 0.0744889\n",
      "[800]\tvalid_0's l1: 0.0744595\n",
      "Early stopping, best iteration is:\n",
      "[864]\tvalid_0's l1: 0.0744348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.074310: 100%|##########| 6/6 [03:43<00:00, 42.25s/it]\u001b[32m[I 2021-06-09 13:32:43,462]\u001b[0m Trial 42 finished with value: 0.07443483241393954 and parameters: {'feature_fraction': 0.58}. Best is trial 38 with value: 0.07431009298773159.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.074310: 100%|##########| 6/6 [03:43<00:00, 37.28s/it]\n",
      "regularization_factors, val_score: 0.074310:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752937\n",
      "[400]\tvalid_0's l1: 0.0745418\n",
      "[600]\tvalid_0's l1: 0.0743631\n",
      "[800]\tvalid_0's l1: 0.0742943\n",
      "[1000]\tvalid_0's l1: 0.0742805\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[946]\tvalid_0's l1: 0.0742704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074270:   5%|5         | 1/20 [00:56<17:57, 56.72s/it]\u001b[32m[I 2021-06-09 13:33:40,192]\u001b[0m Trial 43 finished with value: 0.07427041974860914 and parameters: {'lambda_l1': 0.6138418417287578, 'lambda_l2': 2.2423639142955216e-08}. Best is trial 43 with value: 0.07427041974860914.\u001b[0m\n",
      "regularization_factors, val_score: 0.074270:   5%|5         | 1/20 [00:56<17:57, 56.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753459\n",
      "[400]\tvalid_0's l1: 0.0746413\n",
      "[600]\tvalid_0's l1: 0.0744324\n",
      "[800]\tvalid_0's l1: 0.0743502\n",
      "[1000]\tvalid_0's l1: 0.0742931\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[986]\tvalid_0's l1: 0.0742898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074270:  10%|#         | 2/20 [01:43<15:10, 50.58s/it]\u001b[32m[I 2021-06-09 13:34:26,479]\u001b[0m Trial 44 finished with value: 0.0742898145838138 and parameters: {'lambda_l1': 4.359654161669708e-05, 'lambda_l2': 3.3289914013295397e-06}. Best is trial 43 with value: 0.07427041974860914.\u001b[0m\n",
      "regularization_factors, val_score: 0.074270:  10%|#         | 2/20 [01:43<15:10, 50.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753559\n",
      "[400]\tvalid_0's l1: 0.0747111\n",
      "[600]\tvalid_0's l1: 0.0744809\n",
      "[800]\tvalid_0's l1: 0.074388\n",
      "[1000]\tvalid_0's l1: 0.0743749\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[956]\tvalid_0's l1: 0.0743633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074270:  15%|#5        | 3/20 [02:30<13:56, 49.21s/it]\u001b[32m[I 2021-06-09 13:35:14,051]\u001b[0m Trial 45 finished with value: 0.07436331679400468 and parameters: {'lambda_l1': 0.13100612215298554, 'lambda_l2': 0.0009475900308821168}. Best is trial 43 with value: 0.07427041974860914.\u001b[0m\n",
      "regularization_factors, val_score: 0.074270:  15%|#5        | 3/20 [02:30<13:56, 49.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.075341\n",
      "[400]\tvalid_0's l1: 0.0746733\n",
      "[600]\tvalid_0's l1: 0.074479\n",
      "[800]\tvalid_0's l1: 0.074437\n",
      "[1000]\tvalid_0's l1: 0.0744036\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.074403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074270:  20%|##        | 4/20 [03:16<12:45, 47.87s/it]\u001b[32m[I 2021-06-09 13:35:59,871]\u001b[0m Trial 46 finished with value: 0.07440300064639148 and parameters: {'lambda_l1': 3.832483083210303e-07, 'lambda_l2': 0.00021464862088735028}. Best is trial 43 with value: 0.07427041974860914.\u001b[0m\n",
      "regularization_factors, val_score: 0.074270:  20%|##        | 4/20 [03:16<12:45, 47.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752254\n",
      "[400]\tvalid_0's l1: 0.0744948\n",
      "[600]\tvalid_0's l1: 0.0742989\n",
      "[800]\tvalid_0's l1: 0.0742421\n",
      "[1000]\tvalid_0's l1: 0.0741764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's l1: 0.0741756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074176:  25%|##5       | 5/20 [04:13<12:46, 51.07s/it]\u001b[32m[I 2021-06-09 13:36:56,608]\u001b[0m Trial 47 finished with value: 0.07417561797921877 and parameters: {'lambda_l1': 0.5473987071809883, 'lambda_l2': 8.01793630612081}. Best is trial 47 with value: 0.07417561797921877.\u001b[0m\n",
      "regularization_factors, val_score: 0.074176:  25%|##5       | 5/20 [04:13<12:46, 51.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752792\n",
      "[400]\tvalid_0's l1: 0.0745274\n",
      "[600]\tvalid_0's l1: 0.0743329\n",
      "[800]\tvalid_0's l1: 0.074311\n",
      "Early stopping, best iteration is:\n",
      "[778]\tvalid_0's l1: 0.07429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074176:  30%|###       | 6/20 [05:02<11:47, 50.50s/it]\u001b[32m[I 2021-06-09 13:37:46,014]\u001b[0m Trial 48 finished with value: 0.07428995237754157 and parameters: {'lambda_l1': 0.46418767704013997, 'lambda_l2': 9.502930251228563e-07}. Best is trial 47 with value: 0.07417561797921877.\u001b[0m\n",
      "regularization_factors, val_score: 0.074176:  30%|###       | 6/20 [05:02<11:47, 50.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752956\n",
      "[400]\tvalid_0's l1: 0.0746354\n",
      "[600]\tvalid_0's l1: 0.0743804\n",
      "[800]\tvalid_0's l1: 0.0743239\n",
      "[1000]\tvalid_0's l1: 0.0742672\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's l1: 0.0742672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074176:  35%|###5      | 7/20 [05:50<10:44, 49.61s/it]\u001b[32m[I 2021-06-09 13:38:33,796]\u001b[0m Trial 49 finished with value: 0.07426715160934107 and parameters: {'lambda_l1': 0.12019576953544259, 'lambda_l2': 1.3351822298524678e-07}. Best is trial 47 with value: 0.07417561797921877.\u001b[0m\n",
      "regularization_factors, val_score: 0.074176:  35%|###5      | 7/20 [05:50<10:44, 49.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752421\n",
      "[400]\tvalid_0's l1: 0.0744651\n",
      "[600]\tvalid_0's l1: 0.0742666\n",
      "Early stopping, best iteration is:\n",
      "[606]\tvalid_0's l1: 0.0742533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074176:  40%|####      | 8/20 [06:40<09:56, 49.73s/it]\u001b[32m[I 2021-06-09 13:39:23,773]\u001b[0m Trial 50 finished with value: 0.07425332353107442 and parameters: {'lambda_l1': 1.0802412019365513, 'lambda_l2': 2.4570350051632733e-08}. Best is trial 47 with value: 0.07417561797921877.\u001b[0m\n",
      "regularization_factors, val_score: 0.074176:  40%|####      | 8/20 [06:40<09:56, 49.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753799\n",
      "[400]\tvalid_0's l1: 0.0746953\n",
      "[600]\tvalid_0's l1: 0.0744959\n",
      "[800]\tvalid_0's l1: 0.0744034\n",
      "[1000]\tvalid_0's l1: 0.0743767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[988]\tvalid_0's l1: 0.0743716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074176:  45%|####5     | 9/20 [07:26<08:55, 48.68s/it]\u001b[32m[I 2021-06-09 13:40:10,155]\u001b[0m Trial 51 finished with value: 0.0743715536587861 and parameters: {'lambda_l1': 9.219572487828888e-07, 'lambda_l2': 0.013781165245123857}. Best is trial 47 with value: 0.07417561797921877.\u001b[0m\n",
      "regularization_factors, val_score: 0.074176:  45%|####5     | 9/20 [07:26<08:55, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752729\n",
      "[400]\tvalid_0's l1: 0.0746571\n",
      "[600]\tvalid_0's l1: 0.0744297\n",
      "[800]\tvalid_0's l1: 0.0743322\n",
      "Early stopping, best iteration is:\n",
      "[808]\tvalid_0's l1: 0.0743289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074176:  50%|#####     | 10/20 [08:09<07:49, 46.91s/it]\u001b[32m[I 2021-06-09 13:40:53,084]\u001b[0m Trial 52 finished with value: 0.0743288623344627 and parameters: {'lambda_l1': 0.0262337211872665, 'lambda_l2': 0.00017529236586836923}. Best is trial 47 with value: 0.07417561797921877.\u001b[0m\n",
      "regularization_factors, val_score: 0.074176:  50%|#####     | 10/20 [08:09<07:49, 46.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753248\n",
      "[400]\tvalid_0's l1: 0.0746908\n",
      "[600]\tvalid_0's l1: 0.0744668\n",
      "[800]\tvalid_0's l1: 0.0743698\n",
      "[1000]\tvalid_0's l1: 0.0743542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[916]\tvalid_0's l1: 0.0743399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.074176:  55%|#####5    | 11/20 [08:55<06:59, 46.57s/it]\u001b[32m[I 2021-06-09 13:41:38,893]\u001b[0m Trial 53 finished with value: 0.07433992537533599 and parameters: {'lambda_l1': 0.0007984534892279892, 'lambda_l2': 1.6750943079447664}. Best is trial 47 with value: 0.07417561797921877.\u001b[0m\n",
      "regularization_factors, val_score: 0.074176:  55%|#####5    | 11/20 [08:55<06:59, 46.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751749\n",
      "[400]\tvalid_0's l1: 0.0741757\n",
      "[600]\tvalid_0's l1: 0.073921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0738472\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[865]\tvalid_0's l1: 0.0738339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834:  60%|######    | 12/20 [09:59<06:54, 51.79s/it]\u001b[32m[I 2021-06-09 13:42:42,615]\u001b[0m Trial 54 finished with value: 0.07383386458297113 and parameters: {'lambda_l1': 7.721924703994452, 'lambda_l2': 9.04861595519274}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834:  60%|######    | 12/20 [09:59<06:54, 51.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752043\n",
      "[400]\tvalid_0's l1: 0.074219\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0739513\n",
      "[800]\tvalid_0's l1: 0.0739051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[881]\tvalid_0's l1: 0.073894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834:  65%|######5   | 13/20 [11:06<06:35, 56.52s/it]\u001b[32m[I 2021-06-09 13:43:50,006]\u001b[0m Trial 55 finished with value: 0.07389400171290868 and parameters: {'lambda_l1': 6.967837459768598, 'lambda_l2': 6.0490381057165825}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834:  65%|######5   | 13/20 [11:06<06:35, 56.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751834\n",
      "[400]\tvalid_0's l1: 0.0742588\n",
      "[600]\tvalid_0's l1: 0.0740446\n",
      "[800]\tvalid_0's l1: 0.0740158\n",
      "Early stopping, best iteration is:\n",
      "[753]\tvalid_0's l1: 0.0740129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834:  70%|#######   | 14/20 [12:08<05:48, 58.10s/it]\u001b[32m[I 2021-06-09 13:44:51,768]\u001b[0m Trial 56 finished with value: 0.07401290898217114 and parameters: {'lambda_l1': 5.16867403175738, 'lambda_l2': 0.7539549170503028}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834:  70%|#######   | 14/20 [12:08<05:48, 58.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751734\n",
      "[400]\tvalid_0's l1: 0.0741745\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0739087\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.073839\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[811]\tvalid_0's l1: 0.0738371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834:  75%|#######5  | 15/20 [13:08<04:53, 58.72s/it]\u001b[32m[I 2021-06-09 13:45:51,941]\u001b[0m Trial 57 finished with value: 0.0738370576223962 and parameters: {'lambda_l1': 9.042333980231046, 'lambda_l2': 0.10587708662441632}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834:  75%|#######5  | 15/20 [13:08<04:53, 58.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0754285\n",
      "[400]\tvalid_0's l1: 0.074729\n",
      "[600]\tvalid_0's l1: 0.0745653\n",
      "[800]\tvalid_0's l1: 0.0745152\n",
      "[1000]\tvalid_0's l1: 0.0744651\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[989]\tvalid_0's l1: 0.0744622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834:  80%|########  | 16/20 [13:55<03:41, 55.30s/it]\u001b[32m[I 2021-06-09 13:46:39,279]\u001b[0m Trial 58 finished with value: 0.07446224930463342 and parameters: {'lambda_l1': 0.0031279807582008296, 'lambda_l2': 0.07988285987908084}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834:  80%|########  | 16/20 [13:55<03:41, 55.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.075383\n",
      "[400]\tvalid_0's l1: 0.0746738\n",
      "[600]\tvalid_0's l1: 0.0744505\n",
      "[800]\tvalid_0's l1: 0.0743406\n",
      "[1000]\tvalid_0's l1: 0.0742782\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[987]\tvalid_0's l1: 0.0742763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834:  85%|########5 | 17/20 [14:41<02:37, 52.36s/it]\u001b[32m[I 2021-06-09 13:47:24,798]\u001b[0m Trial 59 finished with value: 0.07427629747325816 and parameters: {'lambda_l1': 3.678623808966153e-05, 'lambda_l2': 0.10981479045869358}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834:  85%|########5 | 17/20 [14:41<02:37, 52.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751512\n",
      "[400]\tvalid_0's l1: 0.0741561\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0739042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[642]\tvalid_0's l1: 0.0738828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834:  90%|######### | 18/20 [15:32<01:44, 52.04s/it]\u001b[32m[I 2021-06-09 13:48:16,089]\u001b[0m Trial 60 finished with value: 0.07388277629705521 and parameters: {'lambda_l1': 7.818115283385128, 'lambda_l2': 0.0036472028876073062}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834:  90%|######### | 18/20 [15:32<01:44, 52.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753421\n",
      "[400]\tvalid_0's l1: 0.0746701\n",
      "[600]\tvalid_0's l1: 0.0744931\n",
      "[800]\tvalid_0's l1: 0.0744163\n",
      "[1000]\tvalid_0's l1: 0.0743934\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[979]\tvalid_0's l1: 0.0743898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834:  95%|#########5| 19/20 [16:19<00:50, 50.38s/it]\u001b[32m[I 2021-06-09 13:49:02,618]\u001b[0m Trial 61 finished with value: 0.0743897536800968 and parameters: {'lambda_l1': 1.1469413694254171e-08, 'lambda_l2': 0.3285625189172668}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834:  95%|#########5| 19/20 [16:19<00:50, 50.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0753671\n",
      "[400]\tvalid_0's l1: 0.0746901\n",
      "[600]\tvalid_0's l1: 0.0745239\n",
      "[800]\tvalid_0's l1: 0.0744379\n",
      "Early stopping, best iteration is:\n",
      "[825]\tvalid_0's l1: 0.0744311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.073834: 100%|##########| 20/20 [17:04<00:00, 48.78s/it]\u001b[32m[I 2021-06-09 13:49:47,652]\u001b[0m Trial 62 finished with value: 0.07443110401340115 and parameters: {'lambda_l1': 0.005301315563771794, 'lambda_l2': 0.02639711143206972}. Best is trial 54 with value: 0.07383386458297113.\u001b[0m\n",
      "regularization_factors, val_score: 0.073834: 100%|##########| 20/20 [17:04<00:00, 51.21s/it]\n",
      "min_data_in_leaf, val_score: 0.073834:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751672\n",
      "[400]\tvalid_0's l1: 0.0741674\n",
      "[600]\tvalid_0's l1: 0.0739347\n",
      "[800]\tvalid_0's l1: 0.0738733\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[787]\tvalid_0's l1: 0.073855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.073834:  20%|##        | 1/5 [01:06<04:25, 66.34s/it]\u001b[32m[I 2021-06-09 13:50:54,009]\u001b[0m Trial 63 finished with value: 0.0738550484451892 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.0738550484451892.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.073834:  20%|##        | 1/5 [01:06<04:25, 66.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751823\n",
      "[400]\tvalid_0's l1: 0.0742186\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0739429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[639]\tvalid_0's l1: 0.0738913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.073834:  40%|####      | 2/5 [01:57<02:53, 57.67s/it]\u001b[32m[I 2021-06-09 13:51:45,612]\u001b[0m Trial 64 finished with value: 0.07389134813885394 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.0738550484451892.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.073834:  40%|####      | 2/5 [01:57<02:53, 57.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751833\n",
      "[400]\tvalid_0's l1: 0.0742285\n",
      "[600]\tvalid_0's l1: 0.0739511\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0738749\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[774]\tvalid_0's l1: 0.0738726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.073834:  60%|######    | 3/5 [03:00<01:59, 59.93s/it]\u001b[32m[I 2021-06-09 13:52:48,231]\u001b[0m Trial 65 finished with value: 0.07387263911085601 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.0738550484451892.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.073834:  60%|######    | 3/5 [03:00<01:59, 59.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751634\n",
      "[400]\tvalid_0's l1: 0.074184\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0738997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0738445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[805]\tvalid_0's l1: 0.0738418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.073834:  80%|########  | 4/5 [04:02<01:00, 60.68s/it]\u001b[32m[I 2021-06-09 13:53:50,057]\u001b[0m Trial 66 finished with value: 0.07384181698954917 and parameters: {'min_child_samples': 50}. Best is trial 66 with value: 0.07384181698954917.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.073834:  80%|########  | 4/5 [04:02<01:00, 60.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0752258\n",
      "[400]\tvalid_0's l1: 0.0742089\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's l1: 0.0739632\n",
      "[800]\tvalid_0's l1: 0.0738994\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[788]\tvalid_0's l1: 0.0738943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.073834: 100%|##########| 5/5 [05:06<00:00, 61.88s/it]\u001b[32m[I 2021-06-09 13:54:54,055]\u001b[0m Trial 67 finished with value: 0.07389429425459934 and parameters: {'min_child_samples': 10}. Best is trial 66 with value: 0.07384181698954917.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.073834: 100%|##########| 5/5 [05:06<00:00, 61.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elaptedtime: 3594.1476023197174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt_params = {\n",
    "    \"objective\":\"regression\",\n",
    "    \"metric\":\"mae\"\n",
    "}\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "opt=lgb.train(\n",
    "    opt_params,\n",
    "    trains,\n",
    "    valid_sets = valids,\n",
    "    verbose_eval=200,\n",
    "    num_boost_round = 1000,\n",
    "    early_stopping_rounds = 100\n",
    ")\n",
    "end = time.time()\n",
    "print('elaptedtime:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorrect-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12512\n",
      "[LightGBM] [Info] Number of data points in the train set: 521580, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7.218861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's l1: 0.0751749\n",
      "[400]\tvalid_0's l1: 0.0741757\n",
      "[600]\tvalid_0's l1: 0.073921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's l1: 0.0738472\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[865]\tvalid_0's l1: 0.0738339\n"
     ]
    }
   ],
   "source": [
    "# lightGBM\n",
    "import lightgbm as lgb\n",
    "best_params = opt.params\n",
    "model = lgb.train(best_params, trains, valid_sets=valids, num_boost_round=1000, early_stopping_rounds=100, verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "future-control",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07383386646155653"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = model.predict(val_x)\n",
    "mae(vals, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "twelve-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>地区名</th>\n",
       "      <td>21963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>最寄駅：名称</th>\n",
       "      <td>18678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>市区町村名</th>\n",
       "      <td>10140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>建築年</th>\n",
       "      <td>4503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>取引時点</th>\n",
       "      <td>4418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>面積（㎡）</th>\n",
       "      <td>2803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>最寄駅：距離（分）</th>\n",
       "      <td>2766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>都市計画</th>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>都道府県名</th>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>容積率（％）</th>\n",
       "      <td>1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平均価格</th>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>経度</th>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>緯度</th>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今後の利用目的</th>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>建物の構造</th>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>改装</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用途</th>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>取引の事情等</th>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>建ぺい率（％）</th>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           importance\n",
       "地区名             21963\n",
       "最寄駅：名称          18678\n",
       "市区町村名           10140\n",
       "建築年              4503\n",
       "取引時点             4418\n",
       "面積（㎡）            2803\n",
       "最寄駅：距離（分）        2766\n",
       "都市計画             2239\n",
       "都道府県名            1891\n",
       "容積率（％）           1401\n",
       "平均価格             1031\n",
       "経度                833\n",
       "緯度                715\n",
       "今後の利用目的           488\n",
       "建物の構造             438\n",
       "改装                421\n",
       "用途                358\n",
       "取引の事情等            316\n",
       "建ぺい率（％）           305"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model.feature_importance(), index=val_x.columns, columns=[\"importance\"]).sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "composite-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(df_test)\n",
    "df_test[\"取引価格（総額）_log\"] = predict\n",
    "df_test[[\"取引価格（総額）_log\"]].to_csv(\"./output/17_sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "congressional-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>都道府県名</th>\n",
       "      <th>市区町村名</th>\n",
       "      <th>地区名</th>\n",
       "      <th>最寄駅：名称</th>\n",
       "      <th>最寄駅：距離（分）</th>\n",
       "      <th>間取り</th>\n",
       "      <th>面積（㎡）</th>\n",
       "      <th>建築年</th>\n",
       "      <th>建物の構造</th>\n",
       "      <th>用途</th>\n",
       "      <th>...</th>\n",
       "      <th>建ぺい率（％）</th>\n",
       "      <th>容積率（％）</th>\n",
       "      <th>取引時点</th>\n",
       "      <th>改装</th>\n",
       "      <th>取引の事情等</th>\n",
       "      <th>取引価格（総額）_log</th>\n",
       "      <th>緯度</th>\n",
       "      <th>経度</th>\n",
       "      <th>都市距離</th>\n",
       "      <th>平均価格</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1117225</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>新中野町</td>\n",
       "      <td>苫小牧</td>\n",
       "      <td>25.0</td>\n",
       "      <td>３ＬＤＫ</td>\n",
       "      <td>120.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2018.75</td>\n",
       "      <td>未改装</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.431364</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>60.455317</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114724</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>青葉町</td>\n",
       "      <td>青葉</td>\n",
       "      <td>9.0</td>\n",
       "      <td>３ＬＤＫ</td>\n",
       "      <td>70.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2017.75</td>\n",
       "      <td>未改装</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.342423</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>60.455317</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114753</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>青葉町</td>\n",
       "      <td>青葉</td>\n",
       "      <td>3.0</td>\n",
       "      <td>３ＬＤＫ</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2016.50</td>\n",
       "      <td>改装済</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.778151</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>60.455317</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120806</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>表町</td>\n",
       "      <td>苫小牧</td>\n",
       "      <td>8.0</td>\n",
       "      <td>４ＬＤＫ</td>\n",
       "      <td>105.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2011.99</td>\n",
       "      <td>未改装</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.230449</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>60.455317</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117264</th>\n",
       "      <td>北海道</td>\n",
       "      <td>苫小牧市</td>\n",
       "      <td>新中野町</td>\n",
       "      <td>苫小牧</td>\n",
       "      <td>25.0</td>\n",
       "      <td>３ＬＤＫ</td>\n",
       "      <td>90.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>ＲＣ</td>\n",
       "      <td>住宅</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2015.50</td>\n",
       "      <td>未改装</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.204120</td>\n",
       "      <td>42.631246</td>\n",
       "      <td>141.603122</td>\n",
       "      <td>60.455317</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        都道府県名 市区町村名   地区名 最寄駅：名称  最寄駅：距離（分）   間取り  面積（㎡）   建築年 建物の構造  用途  ...  \\\n",
       "ID                                                                        ...   \n",
       "1117225   北海道  苫小牧市  新中野町    苫小牧       25.0  ３ＬＤＫ  120.0  12.0    ＲＣ  住宅  ...   \n",
       "1114724   北海道  苫小牧市   青葉町     青葉        9.0  ３ＬＤＫ   70.0  35.0    ＲＣ  住宅  ...   \n",
       "1114753   北海道  苫小牧市   青葉町     青葉        3.0  ３ＬＤＫ   70.0  31.0    ＲＣ  住宅  ...   \n",
       "1120806   北海道  苫小牧市    表町    苫小牧        8.0  ４ＬＤＫ  105.0  18.0    ＲＣ  住宅  ...   \n",
       "1117264   北海道  苫小牧市  新中野町    苫小牧       25.0  ３ＬＤＫ   90.0  15.0    ＲＣ  住宅  ...   \n",
       "\n",
       "        建ぺい率（％） 容積率（％）     取引時点   改装  取引の事情等 取引価格（総額）_log         緯度  \\\n",
       "ID                                                                     \n",
       "1117225    60.0  200.0  2018.75  未改装     NaN     7.431364  42.631246   \n",
       "1114724    60.0  200.0  2017.75  未改装     NaN     6.342423  42.631246   \n",
       "1114753    60.0  200.0  2016.50  改装済     NaN     6.778151  42.631246   \n",
       "1120806    80.0  400.0  2011.99  未改装     NaN     7.230449  42.631246   \n",
       "1117264    60.0  200.0  2015.50  未改装     NaN     7.204120  42.631246   \n",
       "\n",
       "                 経度       都市距離      平均価格  \n",
       "ID                                        \n",
       "1117225  141.603122  60.455317  0.092308  \n",
       "1114724  141.603122  60.455317  0.092308  \n",
       "1114753  141.603122  60.455317  0.092308  \n",
       "1120806  141.603122  60.455317  0.092308  \n",
       "1117264  141.603122  60.455317  0.092308  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-transparency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
